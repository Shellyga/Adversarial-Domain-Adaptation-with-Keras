{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gan Working last chance Adversarial-Domain-Adaptation-with-Keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shellyga/Adversarial-Domain-Adaptation-with-Keras/blob/master/Gan_Working_last_chance_Adversarial_Domain_Adaptation_with_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqYXgaotqk_g",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57CQpjm7OklS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "b2e0c3d4-74d5-4f05-871b-8a3a41f23b36"
      },
      "source": [
        "pip install keras_vggface"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras_vggface in /usr/local/lib/python3.6/dist-packages (0.6)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras_vggface) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras_vggface) (3.13)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras_vggface) (2.4.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from keras_vggface) (7.0.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras_vggface) (2.10.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras_vggface) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras_vggface) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QRBh_1U7qUC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "d38c67f9-bbac-4acb-f5d5-fa97cad35a5c"
      },
      "source": [
        "pip install keras_applications"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras_applications in /usr/local/lib/python3.6/dist-packages (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras_applications) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras_applications) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras_applications) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bxcy4fLWqpgf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import random\n",
        "# import numpy as np\n",
        "# from keras.models import Model\n",
        "# from keras.applications.resnet50 import ResNet50\n",
        "# from keras.layers import Input, Conv2D, MaxPool2D, Flatten, Dense,Reshape\n",
        "# from keras.layers import BatchNormalization, Activation, Dropout\n",
        "# # from keras_vggface.vggface import VGGFace\n",
        "# # from sklearn.preprocessing import LabelEncoder\n",
        "# # from sklearn.model_selection import train_test_split\n",
        "# from keras_vggface.vggface import VGGFace\n",
        "\n",
        "\n",
        "# def build_embedding(param, inp):\n",
        "#     network = eval('VGGFace')\n",
        "#     base = network(weights = 'vggface', include_top = False)\n",
        "#     # base = network(model='resnet50', weights = 'vggface', include_top = False)\n",
        "#     feat = base(inp)\n",
        "#     print(feat.shape)\n",
        "#     flat = Flatten()(feat)\n",
        "#     return flat\n",
        "\n",
        "\n",
        "# def build_classifier(param, embedding):\n",
        "#     # embedding = Input(embedding.shape)\n",
        "#     # embedding = Input( (None, 100352) )\n",
        "#     # embedding = Input( (None, 25088) )\n",
        "#     embedding = Input( (None, 25088) )\n",
        "#     # embedding = Reshape((-1,))(embedding)\n",
        "#     # flat = Flatten()(embedding)\n",
        "#     dense1 = Dense(400, name = 'class_dense1')(embedding)\n",
        "#     bn1 = BatchNormalization(name = 'class_bn1')(dense1)\n",
        "#     act1 = Activation('relu', name = 'class_act1')(bn1)\n",
        "#     drop2 = Dropout(param[\"drop_classifier\"], name = 'class_drop1')(act1)\n",
        "\n",
        "#     dense2 = Dense(100, name = 'class_dense2')(drop2)\n",
        "#     bn2 = BatchNormalization(name = 'class_bn2')(dense2)\n",
        "#     act2 = Activation('relu', name = 'class_act2')(bn2)\n",
        "#     drop2 = Dropout(param[\"drop_classifier\"], name = 'class_drop2')(act2)\n",
        "#     densel = Dense(param[\"number_of_classe\"], name = 'class_dense_last')(drop2)\n",
        "#     # densel = Dense(param[\"source_label\"].shape[1], name = 'class_dense_last')(drop2)\n",
        "#     bnl = BatchNormalization(name = 'class_bn_last')(densel)\n",
        "#     actl = Activation('softmax', name = 'class_act_last')(bnl)\n",
        "#     return Model(input=embedding, outputs=actl)\n",
        "\n",
        "# def build_discriminator(param, embedding):\n",
        "#     # embedding = Input(embedding.shape)\n",
        "#     # embedding = Input( (None, 100352) )\n",
        "#     embedding = Input( (None, 25088) )\n",
        "#     # embedding = Reshape((-1,))(embedding)\n",
        "#     # flat = Flatten()(embedding)\n",
        "#     dense1 = Dense(400, name = 'dis_dense1')(embedding)\n",
        "#     bn1 = BatchNormalization(name='dis_bn1')(dense1)\n",
        "#     act1 = Activation('relu', name = 'dis_act1')(bn1)\n",
        "#     drop1 = Dropout(param[\"drop_discriminator\"], name = 'dis_drop1')(act1)\n",
        "\n",
        "#     dense2 = Dense(100, name = 'dis_dense2')(drop1)\n",
        "#     bn2 = BatchNormalization(name='dis_bn2')(dense2)\n",
        "#     act2 = Activation('relu', name = 'dis_act2')(bn2)\n",
        "#     drop2 = Dropout(param[\"drop_discriminator\"], name = 'dis_drop2')(act2)\n",
        "\n",
        "#     densel = Dense(1, name = 'dis_dense_last')(drop2)\n",
        "#     bnl = BatchNormalization(name = 'dis_bn_last')(densel)\n",
        "#     actl = Activation('sigmoid', name = 'dis_act_last')(bnl)\n",
        "#     return Model(input=embedding, outputs=actl)\n",
        "\n",
        "# def build_combined_classifier(inp, classifier):\n",
        "#     comb_model = Model(inputs = inp, outputs = [classifier])\n",
        "#     return comb_model\n",
        "\n",
        "# def build_combined_discriminator(inp, discriminator):\n",
        "#     comb_model = Model(inputs = inp, outputs = [discriminator])\n",
        "#     return comb_model\n",
        "\n",
        "# def build_combined_model(inp, comb):\n",
        "#     comb_model = Model(inputs = inp, outputs = comb)\n",
        "#     return comb_model"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSkc3pzA6AVU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from keras.models import Model,clone_model\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.layers import Input, Conv2D, MaxPool2D, Flatten, Dense,Reshape\n",
        "from keras.layers import BatchNormalization, Activation, Dropout\n",
        "from keras_vggface.vggface import VGGFace\n",
        "from keras.models import load_model\n",
        "\n",
        "def build_embedding(param):\n",
        "    inp = Input(shape= param[\"inp_dims\"])\n",
        "    network = eval('VGGFace')\n",
        "    base = network(weights = 'vggface', include_top = False)\n",
        "    # base = network(weights = 'imagenet', include_top = False)\n",
        "    feat = base(inp)\n",
        "    return Model(inp,feat)\n",
        "    # print(feat.shape)\n",
        "    # flat = Flatten()(feat)\n",
        "    # return flat\n",
        "\n",
        "# def build_embedding(param,inp):\n",
        "#     model = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3), weights='vggface', pooling='avg')\n",
        "#     feat = model.get_layer('avg_pool').output\n",
        "#     # return feat\n",
        "#     # print(feat.shape)\n",
        "#     flat = Flatten()(feat)\n",
        "#     # flat = Reshape((-1,))(feat)\n",
        "#     # flat = Flatten()(embedding)\n",
        "#     # print(flat.shape)\n",
        "#     return flat\n",
        "\n",
        "def build_classifier(param, embedding):\n",
        "    # embedding = Input(embedding.shape)\n",
        "    # embedding = Input( (None, 100352) )\n",
        "    # embedding = Input( embedding.output)\n",
        "    # embedding = Reshape((-1,))(embedding)\n",
        "    flat = Flatten()(embedding.output)\n",
        "    # dense1 = Dense(400, name = 'class_dense1')(flat)\n",
        "    # bn1 = BatchNormalization(name = 'class_bn1')(dense1)\n",
        "    # act1 = Activation('relu', name = 'class_act1')(bn1)\n",
        "    # drop2 = Dropout(param[\"drop_classifier\"], name = 'class_drop1')(act1)\n",
        "\n",
        "    dense2 = Dense(100, name = 'class_dense2')(flat)\n",
        "    bn2 = BatchNormalization(name = 'class_bn2')(dense2)\n",
        "    act2 = Activation('relu', name = 'class_act2')(bn2)\n",
        "    drop2 = Dropout(param[\"drop_classifier\"], name = 'class_drop2')(act2)\n",
        "    densel = Dense(param[\"number_of_classe\"], name = 'class_dense_last')(drop2)\n",
        "    # densel = Dense(param[\"number_of_classe\"], name = 'class_dense_last')(flat)\n",
        "                                                                         \n",
        "    bnl = BatchNormalization(name = 'class_bn_last')(densel)\n",
        "    actl = Activation('softmax', name = 'class_act_last')(bnl)\n",
        "    return Model(inputs=(embedding.input), outputs=(actl))\n",
        "\n",
        "def build_discriminator(param, embedding_shape):\n",
        "    # embedding = Input(embedding.shape)\n",
        "    # embedding = Input( (None, 100352) )\n",
        "    embedding = Input( embedding_shape )\n",
        "    # embedding = Reshape((-1,))(embedding)\n",
        "    flat = Flatten()(embedding)\n",
        "    # dense1 = Dense(400, name = 'dis_dense1')(flat)\n",
        "    # bn1 = BatchNormalization(name='dis_bn1')(dense1)\n",
        "    # act1 = Activation('relu', name = 'dis_act1')(bn1)\n",
        "    # drop1 = Dropout(param[\"drop_discriminator\"], name = 'dis_drop1')(act1)\n",
        "\n",
        "    dense2 = Dense(100, name = 'dis_dense2')(flat)\n",
        "    bn2 = BatchNormalization(name='dis_bn2')(dense2)\n",
        "    act2 = Activation('relu', name = 'dis_act2')(bn2)\n",
        "    drop2 = Dropout(param[\"drop_discriminator\"], name = 'dis_drop2')(act2)\n",
        "\n",
        "    # densel = Dense(1, name = 'dis_dense_last')(drop2)\n",
        "    densel = Dense(1, name = 'dis_dense_last')(flat)\n",
        "\n",
        "    bnl = BatchNormalization(name = 'dis_bn_last')(densel)\n",
        "    actl = Activation('sigmoid', name = 'dis_act_last')(bnl)\n",
        "    return Model(embedding, actl)\n",
        "\n",
        "# def build_combined_classifier(inp, classifier):\n",
        "#     comb_model = Model(inputs = inp, outputs = [classifier])\n",
        "#     return comb_model\n",
        "\n",
        "# def build_combined_discriminator(inp, discriminator):\n",
        "#     comb_model = Model(inputs = inp, outputs = [discriminator])\n",
        "#     return comb_model\n",
        "\n",
        "def build_combined_model(inp, comb):\n",
        "    comb_model = Model(inputs = inp, outputs = comb)\n",
        "    return comb_model"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DrTIu1SqtIe",
        "colab_type": "text"
      },
      "source": [
        "# Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ve8K7kUmqu5W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "def opt_classifier(param):\n",
        "    return Adam(lr=param[\"lr_classifier\"], beta_1=param[\"b1_classifier\"], beta_2=param[\"b2_classifier\"])\n",
        "\n",
        "def opt_discriminator(param):\n",
        "    return Adam(lr=param[\"lr_discriminator\"], beta_1=param[\"b1_discriminator\"], beta_2=param[\"b2_discriminator\"])\n",
        "\n",
        "def opt_combined(param):\n",
        "    return Adam(lr=param[\"lr_combined\"], beta_1=param[\"b1_combined\"], beta_2=param[\"b2_combined\"])\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHRxvLjYqwvG",
        "colab_type": "text"
      },
      "source": [
        "# Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZPFQrHKAotL",
        "colab_type": "text"
      },
      "source": [
        "# Changes I made"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxlgU5w6qyJO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "e2748e8c-72e3-49f6-82fd-547cf57aef87"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwuSxj4hW9vo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SEED = 7\n",
        "import os\n",
        "import sys\n",
        "import argparse\n",
        "import random\n",
        "import numpy as np\n",
        "# import tensorflow.python.keras as tf\n",
        "from tensorflow.compat.v1 import set_random_seed\n",
        "# import tensorflow.python.keras as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from plotnine import *\n",
        "import pandas as pd\n",
        "                \n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from math import ceil\n",
        "from sklearn.utils import shuffle as skshuffle\n",
        "\n",
        "from imutils import paths\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "os.environ['PYTHONHASHSEED']=str(SEED)\n",
        "np.random.seed(SEED)\n",
        "set_random_seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "from PIL import Image\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Input\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import multi_gpu_model\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pickle\n",
        "\n",
        "\n",
        "def pil_loader(path):\n",
        "    # print(path)\n",
        "    # Return the RGB variant of input image\n",
        "    with open(path, 'rb') as f:\n",
        "      with Image.open(f) as img:\n",
        "        return img.convert('RGB')\n",
        "\n",
        "def one_hot_encoding(param):\n",
        "    lb = LabelEncoder()\n",
        "    source_labels,target_labels  = lb.fit_transform( param[\"source_label\"]),lb.fit_transform( param[\"target_label\"])\n",
        "    param[\"number_of_classe\"] = len(lb.classes_)\n",
        "    f = open(os.path.join(param[\"output_path\"], 'label(mix_data)'),\"wb\")\n",
        "    f.write(pickle.dumps(lb))\n",
        "    f.close()\n",
        "    source_labels,target_labels = to_categorical(source_labels),to_categorical(target_labels)\n",
        "    return source_labels,target_labels\n",
        "\n",
        "            \n",
        "def data_loader(filepath, inp_dims):\n",
        "    # Load images and corresponding labels from the text file, stack them in numpy arrays and return\n",
        "    # if not os.path.isfile(filepath):\n",
        "    #     print(\"File path {} does not exist. Exiting...\".format(filepath))\n",
        "        # sys.exit() \n",
        "    img = []\n",
        "    label = []\n",
        "    detector = dlib.get_frontal_face_detector()\n",
        "    predictor = \"drive/My Drive/pro_data/shape_predictor_5_face_landmarks.dat\"\n",
        "    # with open(filepath,'r',encoding='utf-8-sig') as fp:\n",
        "    #     for line in fp:\n",
        "    #         token = line.split()\n",
        "    #         image_path = \"drive/My Drive/final_proj_dataset/\"+token[0]\n",
        "    # grab the image paths\n",
        "    imagePaths = sorted(list(paths.list_images(filepath)))\n",
        "    # loop over the input images\n",
        "    for imagePath in imagePaths:\n",
        "        # extract the class label from the image path and update the\n",
        "        # labels list\n",
        "        l = imagePath.split(os.path.sep)[-2]\n",
        "        label.append(l)\n",
        "        i = pil_loader(imagePath)\n",
        "        # i = cv2.imread(imagePath)\n",
        "        i = i.resize((inp_dims[0], inp_dims[1]), Image.ANTIALIAS)\n",
        "        frame_1 = align_and_crop(detector, np.array(i), predictor)[0]\n",
        "        frame_1 = cv2.resize(frame_1,(inp_dims[0], inp_dims[1]))\n",
        "        img.append(frame_1)\n",
        "        # label.append(int(token[1]))\n",
        "    # img, label = skshuffle(img, label) \n",
        "    #todo add picke to save labels (import pickle)\n",
        "    img = np.array(img)\n",
        "    label = np.array(label)\n",
        "    return img, label\n",
        "    \n",
        "\n",
        "def batch_generator(data, batch_size):\n",
        "    #Generate batches of data.\n",
        "    all_examples_indices = len(data[0])\n",
        "    while True:\n",
        "        mini_batch_indices = np.random.choice(all_examples_indices, size = batch_size, replace = False)\n",
        "        tbr = [k[mini_batch_indices] for k in data]\n",
        "        yield tbr\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lE5GvMe6AsOX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(param):\n",
        "    models = {}\n",
        "    inp = Input(shape = (param[\"inp_dims\"]))\n",
        "    # embedding = build_embedding(param, inp) \n",
        "    embedding = build_embedding(param)   \n",
        "    embedding.summary()\n",
        "    # Build and compile the discriminator\n",
        "    discriminator = build_discriminator(param, embedding.output_shape[1:])\n",
        "\n",
        "    # The discriminator takes the representaton as input and determines the domain\n",
        "    models[\"combined_discriminator\"] = Model(inputs=embedding.input, outputs=discriminator(embedding.output))\n",
        "    models[\"combined_discriminator\"].summary()\n",
        "    models[\"combined_discriminator\"].compile(optimizer = opt_discriminator(param), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "    # For the combined model we will only train the generator\n",
        "    discriminator.trainable = False\n",
        "  \n",
        "    # Build the classifier\n",
        "    models['combined_classifier'] = build_classifier(param, embedding)\n",
        "    # models['combined_classifier'] = Model(inputs=embedding.input, outputs=classifier(embedding.input))\n",
        "    models[\"combined_discriminator\"].summary()\n",
        "    models[\"combined_classifier\"].compile(optimizer = opt_classifier(param), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "\n",
        "    # score_Target = models[\"combined_classifier\"].evaluate(param[\"target_data\"], param[\"target_label\"], verbose=0)\n",
        "    # print(\"%s: %.2f%%\" % (models[\"combined_classifier\"].metrics_names[1], score_Target[1]*100))\n",
        "\n",
        "    models[\"combined_model\"] = build_combined_model(embedding.input, [models[\"combined_classifier\"].output, models[\"combined_discriminator\"].output]) \n",
        "    # models[\"combined_model\"] = build_combined_model(inp, [freezed_classifier(embedding), discriminator(embedding)]) \n",
        "    models[\"combined_model\"].compile(optimizer = opt_combined(param), loss = ['categorical_crossentropy', 'binary_crossentropy'] , loss_weights =  [param[\"class_loss_weight\"],  param[\"dis_loss_weight\"]], metrics = ['accuracy'])\n",
        "\n",
        "    # models[\"combined_classifier\"].summary()\n",
        "    # models[\"combined_discriminator\"].summary()\n",
        "    models[\"combined_model\"].summary()\n",
        "\n",
        "    Xs, ys = param[\"source_data\"], param[\"source_label\"]\n",
        "    Xt, yt = param[\"target_data\"], param[\"target_label\"]\n",
        "\n",
        "    Xt, Xt_test, yt, yt_test = param[\"Xt_train\"], param[\"Xt_test\"], param[\"yt_train\"], param[\"yt_test\"]\n",
        "    Xs, Xs_test, ys, ys_test = param[\"Xs_train\"], param[\"Xs_test\"], param[\"ys_train\"], param[\"ys_test\"]\n",
        "    \n",
        "    Xs, ys = aug_training_set_loader(Xs, ys, param[\"inp_dims\"])\n",
        "    Xt, yt = aug_training_set_loader(Xt, yt, param[\"inp_dims\"])\n",
        "\n",
        "    Xs_test, ys_test = skshuffle( Xs_test, ys_test)\n",
        "    Xt_test, yt_test = skshuffle( Xt_test, yt_test)\n",
        "\n",
        "    # Source domain is represented by label 0 and Target by 1\n",
        "    ys_adv = np.array(([0.] * ys.shape[0]))\n",
        "    yt_adv = np.array(([1.] * yt.shape[0]))\n",
        "\n",
        "    y_advb_1 = np.array(([1] * param[\"batch_size\"] + [0] * param[\"batch_size\"])) # For gradient reversal\n",
        "    y_advb_2 = np.array(([0] * param[\"batch_size\"] + [1] * param[\"batch_size\"]))\n",
        "    weight_class = np.array(([1] * param[\"batch_size\"] + [0] * param[\"batch_size\"]))\n",
        "    weight_adv = np.ones((param[\"batch_size\"] * 2,))\n",
        "    S_batches = batch_generator([Xs, ys], param[\"batch_size\"])\n",
        "    T_batches = batch_generator([Xt, np.zeros(shape = (len(Xt),))], param[\"batch_size\"])\n",
        "\n",
        "    param[\"target_accuracy\"] = 0\n",
        "\n",
        "    optim = {}\n",
        "    optim[\"iter\"] = 0\n",
        "    optim[\"acc\"] = \"\"\n",
        "    optim[\"labels\"] = np.array(Xt.shape[0],)\n",
        "    gap_last_snap = 0\n",
        "\n",
        "    acc_source=[]\n",
        "    acc_target=[]\n",
        "    acc_domain_source=[]\n",
        "    acc_domain_target=[]\n",
        "    loss_discriminator = []\n",
        "    loss_classifier_source=[]\n",
        "\n",
        "    t_domain_label = np.ones(( param[\"batch_size\"], 1))\n",
        "    s_domain_label = np.zeros(( param[\"batch_size\"], 1))\n",
        "    for i in range(param[\"num_iterations\"]):        \n",
        "        Xsb, ysb = next(S_batches)\n",
        "        Xtb, ytb = next(T_batches)\n",
        "        X_adv = np.concatenate([Xsb, Xtb])\n",
        "        y_class = np.concatenate([ysb, np.zeros_like(ysb)])\n",
        "        # print(X_adv.shape)\n",
        "        # plt.imshow(X_adv[0])\n",
        "        # plt.show()\n",
        "\n",
        "        d_loss = models[\"combined_discriminator\"].train_on_batch(X_adv, y_advb_2)\n",
        "\n",
        "        # ---------------------\n",
        "        #  Train Generator\n",
        "        # ---------------------\n",
        "\n",
        "        # Train the generator (wants discriminator to mistake images domains)\n",
        "        g_loss = models[\"combined_model\"].train_on_batch(X_adv, [y_class, y_advb_1])\n",
        "\n",
        "\n",
        "\n",
        "        if ((i + 1) % param[\"test_interval\"] == 0):\n",
        "            ys_pred = models[\"combined_classifier\"].predict(Xs)\n",
        "            # yt_pred = models[\"combined_classifier\"].predict(Xt)\n",
        "            \n",
        "            ys_adv_pred = models[\"combined_discriminator\"].predict(Xs)\n",
        "            yt_adv_pred = models[\"combined_discriminator\"].predict(Xt)\n",
        "\n",
        "            source_accuracy = accuracy_score(ys.argmax(1), ys_pred.argmax(1))              \n",
        "            # target_accuracy = accuracy_score(yt.argmax(1), yt_pred.argmax(1))\n",
        "            source_domain_accuracy = accuracy_score(ys_adv, np.round(ys_adv_pred))              \n",
        "            target_domain_accuracy = accuracy_score(yt_adv, np.round(yt_adv_pred))\n",
        "\n",
        "            acc_source.append(source_accuracy)\n",
        "            # acc_target.append(target_accuracy)\n",
        "            acc_domain_source.append(source_domain_accuracy)\n",
        "            acc_domain_target.append(target_domain_accuracy)\n",
        "\n",
        "            loss_discriminator.append(d_loss)\n",
        "            loss_classifier_source.append(g_loss)\n",
        "\n",
        "            log_str = \"iter: {:05d}: \\nLABEL CLASSIFICATION: source_accuracy: {:.5f}\\\n",
        "                    \\nDOMAIN DISCRIMINATION: source_domain_accuracy: {:.5f}, target_domain_accuracy: {:.5f} \\n\"\\\n",
        "                                                         .format(i, source_accuracy*100,\n",
        "                                                      source_domain_accuracy*100, target_domain_accuracy*100)\n",
        "            print(log_str)\n",
        "\n",
        "            if ((i + 1) % param[\"test_interval\"] == 0):             \n",
        "            #     optim[\"iter\"] = i\n",
        "            #     optim[\"acc\"] = log_str\n",
        "            #     optim[\"labels\"] = ys_pred.argmax(1)\n",
        "            #     param[\"target_accuracy\"] = target_accuracy\n",
        "                models[\"combined_classifier\"].save('/content/drive/My Drive/pro_data/gan_pro_book_res/ombined_classifier.h5')\n",
        "\n",
        "\n",
        "\n",
        "    models[\"combined_classifier\"].save('/content/drive/My Drive/pro_data/gan_pro_book_res/ombined_classifier.h5')\n",
        "\n",
        "\n",
        "    print(optim[\"iter\"],optim[\"acc\"],optim[\"labels\"])\n",
        "\n",
        "    print(\"Source matrix: \",metrics.confusion_matrix(ys.argmax(1), ys_pred.argmax(1)))\n",
        "    print(\"Target matrix: \",metrics.confusion_matrix(yt.argmax(1), yt_pred.argmax(1)))\n",
        "\n",
        "    ys_test_pred = models[\"combined_classifier\"].predict(Xs_test)\n",
        "    yt_test_pred = models[\"combined_classifier\"].predict(Xt_test)\n",
        "    source_accuracy_test = accuracy_score(ys_test.argmax(1), ys_test_pred.argmax(1))              \n",
        "    target_accuracy_test = accuracy_score(yt_test.argmax(1), yt_test_pred.argmax(1))\n",
        "\n",
        "    print(\"source accuracy test\",source_accuracy_test)\n",
        "    print(\"target accuracy test\",target_accuracy_test)\n",
        "\n",
        "    print(\"Source matrix: \",metrics.confusion_matrix(ys_test.argmax(1), ys_test_pred.argmax(1)))\n",
        "    print(\"Target matrix: \",metrics.confusion_matrix(yt_test.argmax(1), yt_test_pred.argmax(1)))\n",
        "\n",
        "\n",
        "    N = np.arange(0,len(acc_source))\n",
        "\n",
        "    plt.style.use(\"ggplot\")\n",
        "    plt.figure()\n",
        "    plt.plot(N, np.array(acc_source), label=\"Source accuracy\")\n",
        "    # plt.plot(N, np.array(acc_target), label=\"Target accuracy\")\n",
        "    plt.title(\"Training Accuracy of Source\")\n",
        "    plt.xlabel(\"Number of intervals\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    plt.savefig('/content/drive/My Drive/pro_data/gan_pro_book_res/classifier_graph.png')\n",
        "\n",
        "\n",
        "    plt.style.use(\"ggplot\")\n",
        "    plt.figure()\n",
        "    plt.plot(N, np.array(acc_domain_source), label=\"Domain Source accuracy\")\n",
        "    plt.plot(N, np.array(acc_domain_target), label=\"Domain Target accuracy\")\n",
        "    plt.title(\"Training Accuracy of Source and Target \")\n",
        "    plt.xlabel(\"Number of intervals\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    plt.savefig('/content/drive/My Drive/pro_data/gan_‏pro_book_res/discriminator_graph.png')\n",
        "\n",
        "    plt.style.use(\"ggplot\")\n",
        "    plt.figure()\n",
        "    plt.plot(N, np.array(loss_classifier_source), label=\"Combined Model ACC / Loss\")\n",
        "    plt.plot(N, np.array(loss_discriminator), label=\"Discriminator Acc / loss\")\n",
        "    plt.title(\"Training Loss and Accuracy of Source and Target \")\n",
        "    plt.xlabel(\"Number of intervals\")\n",
        "    plt.ylabel(\"Acc/ Loss\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    plt.savefig('/content/drive/My Drive/pro_data/gan_pro_book_res/train_on_batch_graph.png')\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdnIND2JEHUn",
        "colab_type": "text"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sq_tQgLEEETm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "if __name__ == \"__main__\":\n",
        "    # Read parameter values from the console\n",
        "    parser = argparse.ArgumentParser(description = 'Domain Adaptation')\n",
        "    parser.add_argument('--number_of_gpus', type = int, nargs = '?', default = '1', help = \"Number of gpus to run\")\n",
        "    parser.add_argument('--network_name', type = str, default = 'ResNet50', help = \"Name of the feature extractor network\")\n",
        "    parser.add_argument('--dataset_name', type = str, default = 'Office', help = \"Name of the source dataset\")\n",
        "    parser.add_argument('--dropout_classifier', type = float, default = 0.25, help = \"Dropout ratio for classifier\")\n",
        "    parser.add_argument('--dropout_discriminator', type = float, default = 0.25, help = \"Dropout ratio for discriminator\")    \n",
        "    parser.add_argument('--source_path', type = str, default = 'amazon_10_list.txt', help = \"Path to source dataset\")\n",
        "    parser.add_argument('--target_path', type = str, default = 'webcam_10_list.txt', help = \"Path to target dataset\")\n",
        "    parser.add_argument('--lr_classifier', type = float, default = 0.0001, help = \"Learning rate for classifier model\")\n",
        "    parser.add_argument('--b1_classifier', type = float, default = 0.9, help = \"Exponential decay rate of first moment \\\n",
        "                                                                                             for classifier model optimizer\")\n",
        "    parser.add_argument('--b2_classifier', type = float, default = 0.999, help = \"Exponential decay rate of second moment \\\n",
        "                                                                                            for classifier model optimizer\")\n",
        "    parser.add_argument('--lr_discriminator', type = float, default = 0.00001, help = \"Learning rate for discriminator model\")\n",
        "    parser.add_argument('--b1_discriminator', type = float, default = 0.9, help = \"Exponential decay rate of first moment \\\n",
        "                                                                                             for discriminator model optimizer\")\n",
        "    parser.add_argument('--b2_discriminator', type = float, default = 0.999, help = \"Exponential decay rate of second moment \\\n",
        "                                                                                            for discriminator model optimizer\")\n",
        "    parser.add_argument('--lr_combined', type = float, default = 0.00001, help = \"Learning rate for combined model\")\n",
        "    parser.add_argument('--b1_combined', type = float, default = 0.9, help = \"Exponential decay rate of first moment \\\n",
        "                                                                                             for combined model optimizer\")\n",
        "    parser.add_argument('--b2_combined', type = float, default = 0.999, help = \"Exponential decay rate of second moment \\\n",
        "                                                                                            for combined model optimizer\")\n",
        "    parser.add_argument('--classifier_loss_weight', type = float, default = 1, help = \"Classifier loss weight\")\n",
        "    parser.add_argument('--discriminator_loss_weight', type = float, default = 4, help = \"Discriminator loss weight\")\n",
        "    parser.add_argument('--batch_size', type = int, default = 32, help = \"Batch size for training\")\n",
        "    parser.add_argument('--test_interval', type = int, default = 3, help = \"Gap between two successive test phases\")\n",
        "    parser.add_argument('--num_iterations', type = int, default = 120, help = \"Number of iterations\")\n",
        "    parser.add_argument('--snapshot_interval', type = int, default = 500, help = \"Minimum gap between saving outputs\")\n",
        "    parser.add_argument('--output_dir', type = str, default = 'Models', help = \"Directory for saving outputs\")\n",
        "    # args = parser.parse_args()\n",
        "\n",
        "    # Set GPU device\n",
        "    # os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(list(np.arange(args.number_of_gpus))).strip('[]')\n",
        "\n",
        "    # Initialize parameters\n",
        "    param = {}\n",
        "    param[\"number_of_gpus\"] = 1\n",
        "    # param[\"network_name\"] = 'ResNet50'\n",
        "    param[\"network_name\"] = 'VGGFace'\n",
        "    param[\"inp_dims\"] = [224, 224, 3]\n",
        "    # param[\"num_iterations\"] = 2\n",
        "    param[\"num_iterations\"] = 650\n",
        "    param[\"lr_classifier\"] = 0.0001\n",
        "    param[\"b1_classifier\"] = 0.9\n",
        "    param[\"b2_classifier\"] = 0.999    \n",
        "    param[\"lr_discriminator\"] = 0.000001\n",
        "    #changed lr of disc \n",
        "    # param[\"lr_discriminator\"] = 0.00001\n",
        "    param[\"b1_discriminator\"] =  0.9\n",
        "    param[\"b2_discriminator\"] = 0.999\n",
        "    param[\"lr_combined\"] = 0.00001\n",
        "    param[\"b1_combined\"] =  0.9\n",
        "    param[\"b2_combined\"] =  0.999       \n",
        "    # param[\"batch_size\"] = int(32)\n",
        "    param[\"batch_size\"] = int(8)\n",
        "    param[\"class_loss_weight\"] = 1\n",
        "    param[\"dis_loss_weight\"] = 4    \n",
        "    param[\"drop_classifier\"] = 0.25\n",
        "    param[\"drop_discriminator\"] = 0.25\n",
        "    param[\"test_interval\"] = 100\n",
        "    param[\"source_path\"] = '/content/drive/My Drive/pro_data/Student_source'\n",
        "    param[\"target_path\"] =  '/content/drive/My Drive/pro_data/alyn_target_3' \n",
        "    param[\"snapshot_interval\"] = 500\n",
        "    # param[\"snapshot_interval\"] = 5\n",
        "    param[\"output_path\"] = '/content/drive/My Drive/pro_data/gan_pro_book_res'\n",
        "    param[\"number_of_classe\"] = 0\n",
        "\n",
        "    # # Create directory for saving models and log files\n",
        "    if not os.path.exists(param[\"output_path\"]):\n",
        "        os.mkdir(param[\"output_path\"])\n",
        "    \n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "   "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42msC3B1fJoH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "85b29a4f-5566-4a03-ed89-b649986fbb8f"
      },
      "source": [
        "print(\"[INFO] loading images...\")\n",
        "# Load source and target data\n",
        "param[\"source_data\"], param[\"source_label\"] = data_loader(param[\"source_path\"], param[\"inp_dims\"])\n",
        "print(\"source images loaded\")\n",
        "print(\"number of images in source domain\", param[\"source_data\"].shape[0])\n",
        "param[\"target_data\"], param[\"target_label\"] = data_loader(param[\"target_path\"], param[\"inp_dims\"])\n",
        "print(\"target images loaded\")\n",
        "print(\"number of images in target domain\", param[\"target_data\"].shape[0])\n",
        "# Encode labels into one-hot format\n",
        "print(\"[INFO] Encode labels into one-hot format\")\n",
        "param[\"source_label\"], param[\"target_label\"] = one_hot_encoding(param)\n",
        "\n",
        "\n",
        "# param[\"Xt_train\"], param[\"Xt_test\"], param[\"yt_train\"], param[\"yt_test\"] = train_test_split(param[\"target_data\"], param[\"target_label\"], test_size=0.2, random_state=42)\n",
        "param[\"Xs_train\"], param[\"Xs_test\"], param[\"ys_train\"], param[\"ys_test\"] = train_test_split(param[\"source_data\"], param[\"source_label\"], test_size=0.2, random_state=42)\n",
        "\n",
        "param[\"Xt_train\"],param[\"yt_train\"] = param[\"target_data\"], param[\"target_label\"]\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading images...\n",
            "source images loaded\n",
            "number of images in source domain 1449\n",
            "target images loaded\n",
            "number of images in target domain 1440\n",
            "[INFO] Encode labels into one-hot format\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcwepu5g4Np0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2b2d1edb-d142-489a-ab76-5f5188c6417a"
      },
      "source": [
        "param[\"Xt_test\"], param[\"yt_test\"] =  data_loader('/content/drive/My Drive/pro_data/testset', param[\"inp_dims\"])\n",
        "\n",
        "lb = LabelEncoder()\n",
        "target_labels  = lb.fit_transform(param[\"yt_test\"])\n",
        "param[\"yt_test\"] = to_categorical(target_labels)\n",
        "f = open('/content/drive/My Drive/pro_data/gan_pro_book_res/_labels',\"wb\")\n",
        "f.write(pickle.dumps(lb))\n",
        "f.close()\n",
        "\n",
        "# print('Xt_train ',param[\"Xt_train\"].shape[0] )\n",
        "print('Xt_test ',param[\"Xt_test\"].shape[0])\n",
        "# print('Xs_train', param[\"Xs_train\"].shape[0] )\n",
        "# print('Xs_test', param[\"Xs_test\"].shape[0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Xt_test  40\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1vaKAXuoj3A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "48438129-5d45-43de-8e6f-7eb962208b22"
      },
      "source": [
        "# Train data\n",
        "print(\"[INFO] training network...\")\n",
        "train(param)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] training network...\n",
            "Model: \"functional_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "vggface_vgg16 (Functional)   (None, None, None, 512)   14714688  \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"functional_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "vggface_vgg16 (Functional)   (None, None, None, 512)   14714688  \n",
            "_________________________________________________________________\n",
            "functional_13 (Functional)   (None, 1)                 25093     \n",
            "=================================================================\n",
            "Total params: 14,739,781\n",
            "Trainable params: 14,739,779\n",
            "Non-trainable params: 2\n",
            "_________________________________________________________________\n",
            "Model: \"functional_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "vggface_vgg16 (Functional)   (None, None, None, 512)   14714688  \n",
            "_________________________________________________________________\n",
            "functional_13 (Functional)   (None, 1)                 25093     \n",
            "=================================================================\n",
            "Total params: 14,739,781\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 25,093\n",
            "_________________________________________________________________\n",
            "Model: \"functional_19\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_6 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "vggface_vgg16 (Functional)      (None, None, None, 5 14714688    input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 25088)        0           vggface_vgg16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "class_dense2 (Dense)            (None, 100)          2508900     flatten_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "class_bn2 (BatchNormalization)  (None, 100)          400         class_dense2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "class_act2 (Activation)         (None, 100)          0           class_bn2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "class_drop2 (Dropout)           (None, 100)          0           class_act2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "class_dense_last (Dense)        (None, 3)            303         class_drop2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "class_bn_last (BatchNormalizati (None, 3)            12          class_dense_last[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "class_act_last (Activation)     (None, 3)            0           class_bn_last[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "functional_13 (Functional)      (None, 1)            25093       vggface_vgg16[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 17,249,396\n",
            "Trainable params: 17,224,097\n",
            "Non-trainable params: 25,299\n",
            "__________________________________________________________________________________________________\n",
            "iter: 00099: \n",
            "LABEL CLASSIFICATION: source_accuracy: 66.60915                    \n",
            "DOMAIN DISCRIMINATION: source_domain_accuracy: 0.86281, target_domain_accuracy: 3.75000 \n",
            "\n",
            "iter: 00199: \n",
            "LABEL CLASSIFICATION: source_accuracy: 79.85332                    \n",
            "DOMAIN DISCRIMINATION: source_domain_accuracy: 0.21570, target_domain_accuracy: 2.88194 \n",
            "\n",
            "iter: 00299: \n",
            "LABEL CLASSIFICATION: source_accuracy: 75.66868                    \n",
            "DOMAIN DISCRIMINATION: source_domain_accuracy: 0.25884, target_domain_accuracy: 3.57639 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64cs_H43doeo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def _plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Greens):\n",
        "    from sklearn.metrics import accuracy_score\n",
        "    from sklearn.metrics import precision_score, recall_score, roc_auc_score, accuracy_score, roc_curve, auc, confusion_matrix\n",
        "    import itertools\n",
        "    \n",
        "\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title, fontsize = 14)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"black\")\n",
        "\n",
        "    plt.ylabel('True Class', fontsize = 14)\n",
        "    plt.xlabel('Predicted Class', fontsize = 14)\n",
        "\n",
        "    plt.tick_params(axis='both', which='major', labelsize=14)\n",
        "    plt.tight_layout()\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVJTvJ20eURF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "cfe1d88a-ddcd-4627-8c98-85e33ffb77ac"
      },
      "source": [
        "import keras\n",
        "path = '/content/drive/My Drive/pro_data/gan_pro_book_res/ombined_classifier.h5'\n",
        "\n",
        "model = keras.models.load_model(path)\n",
        "# ys_test_pred = model.predict(param[\"Xs_test\"])\n",
        "yt_test_pred = model.predict(param[\"Xt_test\"])\n",
        "# ys_test = param[\"ys_test\"]\n",
        "yt_test = param[\"yt_test\"]\n",
        "# labels_path = '/content/drive/My Drive/pro_data/gan_pro_book_res/_labels '\n",
        "# lb = pickle.loads(open(labels_path, \"rb\").read())\n",
        "# classes = lb.classes_\n",
        "\n",
        "# source_accuracy_test = accuracy_score(ys_test.argmax(1), ys_test_pred.argmax(1))              \n",
        "target_accuracy_test = accuracy_score(yt_test.argmax(1), yt_test_pred.argmax(1))\n",
        "\n",
        "# print(\"source accuracy test\",source_accuracy_test)\n",
        "print(\"target accuracy test\",target_accuracy_test)\n",
        "\n",
        "# print(\"Source matrix: \",metrics.confusion_matrix(ys_test.argmax(1), ys_test_pred.argmax(1)))\n",
        "print(\"Target matrix: \",metrics.confusion_matrix(yt_test.argmax(1), yt_test_pred.argmax(1)))\n",
        "\n",
        "# cm_t_sanity_s = metrics.confusion_matrix(ys_test.argmax(1), ys_test_pred.argmax(1))\n",
        "# _plot_confusion_matrix(cm_t_sanity_s, classes,title='Source Confusion matrix')              \n",
        "\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "target accuracy test 0.3\n",
            "Target matrix:  [[ 0  9  0]\n",
            " [ 0  9  7]\n",
            " [ 0 12  3]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9gI-0sSeYSw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "edbd4edd-ee14-4404-d999-eac8d0cdc0e2"
      },
      "source": [
        "cm_t_sanity_t = metrics.confusion_matrix(yt_test.argmax(1), yt_test_pred.argmax(1))\n",
        "_plot_confusion_matrix(cm_t_sanity_t, classes,title='Target Confusion matrix')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCAxthiKjwnr",
        "colab_type": "text"
      },
      "source": [
        "# Augment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xD18oqysj0hG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imgaug import augmenters as iaa\n",
        "from imgaug import seed\n",
        "def aug_training_set_loader(images,labels,inp_dims):\n",
        "    NUM_COPIES = ceil(1000/len(images))\n",
        "    images = np.array(images)\n",
        "    images=augment(inp_dims[0], inp_dims[1], images, NUM_COPIES)\n",
        "    aug_labels =[]\n",
        "    for x in labels:\n",
        "        for i in range(NUM_COPIES+1):  # NUM_COPIES+1-> numbers of augmentations + 1 original\n",
        "            aug_labels.append(x)\n",
        "    images, labels = skshuffle(images, aug_labels)\n",
        "    # images = np.array(images)\n",
        "    images = np.array(images, dtype=\"float\") / 255.0\n",
        "    labels = np.array(labels)\n",
        "    return images, labels\n",
        "\n",
        "def augment(width, height, data, NUM_COPIES):\n",
        "    \"\"\"\n",
        "    preform augmentetion on the list of photos named 'data'\n",
        "    :param width: width of a single photo\n",
        "    :param height: height of a single photo\n",
        "    :param data: a list of photos to augment\n",
        "    :param NUM_COPIES: number of copies produced from the image\n",
        "    :return: a list of photos that consists from the original photos and their augmentations\n",
        "    \"\"\"\n",
        "    augmented_data = []\n",
        "    sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
        "    seq = iaa.Sequential([\n",
        "        sometimes(iaa.Sharpen(alpha=(0.0, 1.0), lightness=(0.75, 2.0))),\n",
        "        sometimes(iaa.Fliplr()),  # horizontal flips\n",
        "        sometimes(iaa.AddElementwise((-50, 50))),\n",
        "        sometimes(iaa.Sometimes(0.5, iaa.GaussianBlur(sigma=(0.0, 2.0)))),\n",
        "        sometimes(iaa.ContrastNormalization((0.8, 1.2))),\n",
        "        sometimes(iaa.Multiply((0.8, 1.2), per_channel=0.2)),\n",
        "        sometimes(iaa.Affine(\n",
        "            scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
        "            translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
        "            shear=(-8, 8)\n",
        "        )),\n",
        "        sometimes(iaa.Superpixels(p_replace=0.1, n_segments=150))\n",
        "    ], random_order=True)  # apply augmenters in random order\n",
        "    for img in data:\n",
        "        copies = augment_image(width, height, img, seq, NUM_COPIES)\n",
        "        copies.append(img.reshape(width, height, 3))\n",
        "        for cpy in copies:\n",
        "            augmented_data.append(cpy)\n",
        "    return augmented_data\n",
        "\n",
        "\n",
        "def augment_image(width, height, image, seq, NUM_COPIES):\n",
        "    \"\"\"\n",
        "        augments a single image\n",
        "    :param width: width of the image\n",
        "    :param height: height of the image\n",
        "    :param image: a matrix representing a rgb image\n",
        "    :param seq: the augmantation sequence preformed\n",
        "    :param NUM_COPIES: number of copies produced from the image\n",
        "    :return: a list of all images made from 'image' not including the original\n",
        "    \"\"\"\n",
        "    seed (1)\n",
        "    copies = []\n",
        "    image = image.reshape(width, height, 3)\n",
        "    for i in range(NUM_COPIES):\n",
        "        copies.append(seq.augment_image(image))\n",
        "\n",
        "    return copies"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqiFjCePj2a1",
        "colab_type": "text"
      },
      "source": [
        "# Crop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSCoB73kj6ux",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import dlib\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import cv2\n",
        "import glob\n",
        "\n",
        "# def resource_path(filename):\n",
        "#     \"\"\" Get absolute path to resource, for the executable\"\"\"\n",
        "#     if getattr(sys, 'frozen', False):\n",
        "#         # The application is frozen\n",
        "#         datadir = os.path.dirname(sys.executable)\n",
        "#     else:\n",
        "#         # The application is not frozen\n",
        "#         # Change this bit to match where you store your data files:\n",
        "#         datadir = os.path.dirname(__file__)\n",
        "\n",
        "    # return os.path.join(datadir, filename)\n",
        "\n",
        "def align_and_crop(detector, im_to_align, predictor_path):\n",
        "    '''\n",
        "    simply aligns the photo (using the detector to identify the eyes) and crops the face.\n",
        "    :param im_to_align: an address of an image\n",
        "    '''\n",
        "\n",
        "    # a shape predictor to find face landmarks so we can precisely localize the face\n",
        "    sp = dlib.shape_predictor(predictor_path)\n",
        "\n",
        "    # Ask the detector to find the bounding boxes of each face. The 1 in the\n",
        "    # second argument indicates that we should upsample the image 1 time.\n",
        "    try:\n",
        "        dets = detector(im_to_align, 1)\n",
        "    except RuntimeError:\n",
        "        return -1\n",
        "\n",
        "    num_faces = len(dets)\n",
        "    if num_faces == 0:\n",
        "        return im_to_align, False\n",
        "\n",
        "    # Find the 5 face landmarks we need to do the alignment.\n",
        "    faces = dlib.full_object_detections()\n",
        "    for detection in dets:\n",
        "        faces.append(sp(im_to_align, detection))\n",
        "\n",
        "    # get a single chip (aligned and cropped)\n",
        "    image = dlib.get_face_chip(im_to_align, faces[0])\n",
        "    # cv2.imshow(\"f\", image) show image for testing\n",
        "    return image, True"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XA7HFj4Rzgj0",
        "colab_type": "text"
      },
      "source": [
        "# Load model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EITQL6jazlp8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load and evaluate a saved model\n",
        "from numpy import loadtxt\n",
        "from keras.models import load_model\n",
        "\n",
        "model_path = 'drive/My Drive/final_proj_dataset/result2/model.h5'\n",
        "# load model\n",
        "model = load_model(model_path)\n",
        "# summarize model.\n",
        "model.summary()\n",
        "# load dataset\n",
        "\n",
        "score_Target = model.evaluate(Xs_test, ys_test, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_dfbPgstK6i",
        "colab_type": "text"
      },
      "source": [
        "# Only Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D16kvdCKtRhD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from keras_vggface.vggface import VGGFace\n",
        "\n",
        "def build_embedding_vgg(param, inp):\n",
        "    network = eval('VGGFace')\n",
        "    base = network(weights = 'vggface', include_top = False)\n",
        "    feat = base(inp)\n",
        "    flat = Flatten()(feat)\n",
        "    return flat\n",
        "\n",
        "def build_classifier_vgg(param, embedding):\n",
        "    dense1 = Dense(400, name = 'class_dense1')(embedding)\n",
        "    bn1 = BatchNormalization(name = 'class_bn1')(dense1)\n",
        "    act1 = Activation('relu', name = 'class_act1')(bn1)\n",
        "    drop2 = Dropout(param[\"drop_classifier\"], name = 'class_drop1')(act1)\n",
        "\n",
        "    dense2 = Dense(100, name = 'class_dense2')(drop2)\n",
        "    bn2 = BatchNormalization(name = 'class_bn2')(dense2)\n",
        "    act2 = Activation('relu', name = 'class_act2')(bn2)\n",
        "    drop2 = Dropout(param[\"drop_classifier\"], name = 'class_drop2')(act2)\n",
        "\n",
        "    densel = Dense(param[\"source_label\"].shape[1], name = 'class_dense_last')(drop2)\n",
        "    bnl = BatchNormalization(name = 'class_bn_last')(densel)\n",
        "    actl = Activation('softmax', name = 'class_act_last')(bnl)\n",
        "    return actl\n",
        "\n",
        "\n",
        "def train_classifier(param):\n",
        "    models = {}\n",
        "    inp = Input(shape = (param[\"inp_dims\"]))\n",
        "    embedding = build_embedding_vgg(param,inp)\n",
        "    classifier = build_classifier_vgg(param, embedding)\n",
        "    \n",
        "    models[\"combined_classifier\"] = Model(inp,classifier)\n",
        "    models[\"combined_classifier\"].compile(optimizer = opt_classifier(param), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "\n",
        "    Xs, ys = param[\"source_data\"], param[\"source_label\"]\n",
        "    Xt, yt = param[\"target_data\"], param[\"target_label\"]\n",
        "\n",
        "    # Xt_train, Xt_test, yt_train, yt_test = train_test_split(Xt, yt, test_size=0.4, random_state=42)\n",
        "    Xs_train, Xs_test, ys_train, ys_test = train_test_split(Xs, ys, test_size=0.4, random_state=42)\n",
        "    Xt_train,yt_train = Xt, yt\n",
        "    Xt_test, yt_test = \n",
        "\n",
        "    S_batches = batch_generator([Xs_train, ys_train], param[\"batch_size\"])\n",
        "    T_batches = batch_generator([Xt_train, np.zeros(shape = (len(Xt_train),))], param[\"batch_size\"])\n",
        "\n",
        "    param[\"target_accuracy\"] = 60\n",
        "\n",
        "    optim = {}\n",
        "    optim[\"iter\"] = 0\n",
        "    optim[\"acc\"] = \"\"\n",
        "    optim[\"labels\"] = np.array(Xt.shape[0],)\n",
        "    gap_last_snap = 0\n",
        "\n",
        "    acc_source=[]\n",
        "    acc_target=[]\n",
        "    acc_domain_source=[]\n",
        "    acc_domain_target=[]\n",
        "\n",
        "    for i in range(param[\"num_iterations\"]):        \n",
        "        Xsb, ysb = next(S_batches)\n",
        "        Xtb, ytb = next(T_batches)\n",
        " \n",
        "\n",
        "        stats1 = models[\"combined_classifier\"].train_on_batch(Xsb, [ysb])\n",
        "\n",
        "        if ((i + 1) % param[\"test_interval\"] == 0):\n",
        "            ys_pred = models[\"combined_classifier\"].predict(Xs_train)\n",
        "            yt_pred = models[\"combined_classifier\"].predict(Xt_train)\n",
        "\n",
        "\n",
        "            source_accuracy = accuracy_score(ys_train.argmax(1), ys_pred.argmax(1))              \n",
        "            target_accuracy = accuracy_score(yt_train.argmax(1), yt_pred.argmax(1))\n",
        "\n",
        "\n",
        "            acc_source.append(source_accuracy)\n",
        "            acc_target.append(target_accuracy)\n",
        "\n",
        "            log_str = \"iter: {:05d}: \\nLABEL CLASSIFICATION: source_accuracy: {:.5f}, target_accuracy: {:.5f}\"\\\n",
        "                                                         .format(i, source_accuracy*100, target_accuracy*100)\n",
        "            print(log_str)\n",
        "\n",
        "            models[\"combined_classifier\"].save('drive/My Drive/pro_data/gan_‏pro_book_res/model.h5')\n",
        "            \n",
        "\n",
        "    print(\"Source matrix: \",metrics.confusion_matrix(ys_train.argmax(1), ys_pred.argmax(1)))\n",
        "    print(\"Target matrix: \",metrics.confusion_matrix(yt_train.argmax(1), yt_pred.argmax(1)))\n",
        "\n",
        "    ys_test_pred = models[\"combined_classifier\"].predict(Xs_test)\n",
        "    yt_test_pred = models[\"combined_classifier\"].predict(Xt_test)\n",
        "    source_accuracy_test = accuracy_score(ys_test.argmax(1), ys_test_pred.argmax(1))              \n",
        "    target_accuracy_test = accuracy_score(yt_test.argmax(1), yt_test_pred.argmax(1))\n",
        "\n",
        "    print(\"source accuracy test\",source_accuracy_test)\n",
        "    print(\"target accuracy test\",target_accuracy_test)\n",
        "\n",
        "    print(\"Source matrix: \",metrics.confusion_matrix(ys_test.argmax(1), ys_test_pred.argmax(1)))\n",
        "    print(\"Target matrix: \",metrics.confusion_matrix(yt_test.argmax(1), yt_test_pred.argmax(1)))\n",
        "\n",
        "\n",
        "    N = np.arange(0,len(acc_source))\n",
        "\n",
        "    plt.style.use(\"ggplot\")\n",
        "    plt.figure()\n",
        "    plt.plot(N, np.array(acc_source), label=\"Source accuracy\")\n",
        "    plt.plot(N, np.array(acc_target), label=\"Target accuracy\")\n",
        "    plt.title(\"Training Accuracy of Source and Target \")\n",
        "    plt.xlabel(\"Number of iteration\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6M1ewVXb1w5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_classifier(param)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pQH37cTxOFF",
        "colab_type": "text"
      },
      "source": [
        "# Discriminative Method "
      ]
    }
  ]
}