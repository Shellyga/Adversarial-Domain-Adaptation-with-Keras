{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Adversarial-Domain-Adaptation-with-Keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOYEXjx2vjT9wrATChdthSp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shellyga/Adversarial-Domain-Adaptation-with-Keras/blob/master/Copy_of_Adversarial_Domain_Adaptation_with_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eL528F1bqeYW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GQgQF0CqiOf",
        "colab_type": "text"
      },
      "source": [
        "# Driver"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_egWQHVLqkNe",
        "colab_type": "code",
        "outputId": "51e243b2-892c-4ebf-c431-eb5657c4255c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        }
      },
      "source": [
        "SEED = 7\n",
        "import os\n",
        "import sys\n",
        "import argparse\n",
        "import random\n",
        "import numpy as np\n",
        "from tensorflow import set_random_seed\n",
        "\n",
        "os.environ['PYTHONHASHSEED']=str(SEED)\n",
        "np.random.seed(SEED)\n",
        "set_random_seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "from PIL import Image\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Input\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import multi_gpu_model\n",
        "from sklearn.metrics import accuracy_score\n",
        "# import model\n",
        "# import optimizer\n",
        "\n",
        "def pil_loader(path):\n",
        "    print(path)\n",
        "    # Return the RGB variant of input image\n",
        "    with open(path, 'rb') as f:\n",
        "        with Image.open(f) as img:\n",
        "            return img.convert('RGB')\n",
        "\n",
        "def one_hot_encoding(param):\n",
        "    # Read the source and target labels from param\n",
        "    s_label = param[\"source_label\"]\n",
        "    t_label = param[\"target_label\"]\n",
        "\n",
        "    # Encode the labels into one-hot format\n",
        "    classes = (np.concatenate((s_label, t_label), axis = 0))\n",
        "    num_classes = np.max(classes)\n",
        "    if 0 in classes:\n",
        "            num_classes = num_classes+1\n",
        "    s_label = to_categorical(s_label, num_classes = num_classes)\n",
        "    t_label = to_categorical(t_label, num_classes = num_classes)\n",
        "    return s_label, t_label\n",
        "            \n",
        "def data_loader(filepath, inp_dims):\n",
        "    # Load images and corresponding labels from the text file, stack them in numpy arrays and return\n",
        "    if not os.path.isfile(filepath):\n",
        "        print(\"File path {} does not exist. Exiting...\".format(filepath))\n",
        "        # sys.exit() \n",
        "    img = []\n",
        "    label = []\n",
        "    with open(filepath,'r') as fp:\n",
        "        for line in fp:\n",
        "            token = line.split()\n",
        "            # print('drive/My Drive/project_data/'+token[0])\n",
        "            image_path = \"drive/My Drive/project_data/\"+token[0]\n",
        "            i = pil_loader(image_path)\n",
        "            i = i.resize((inp_dims[0], inp_dims[1]), Image.ANTIALIAS)\n",
        "            img.append(np.array(i))\n",
        "            label.append(int(token[1]))\n",
        "    img = np.array(img)\n",
        "    label = np.array(label)\n",
        "    return img, label\n",
        "\n",
        "def batch_generator(data, batch_size):\n",
        "    #Generate batches of data.\n",
        "    all_examples_indices = len(data[0])\n",
        "    while True:\n",
        "        mini_batch_indices = np.random.choice(all_examples_indices, size = batch_size, replace = False)\n",
        "        tbr = [k[mini_batch_indices] for k in data]\n",
        "        yield tbr\n",
        "\n",
        "def train(param):\n",
        "    models = {}\n",
        "    inp = Input(shape = (param[\"inp_dims\"]))\n",
        "    embedding = build_embedding(param, inp)\n",
        "    # classifier = build_classifier(param, embedding)\n",
        "    discriminator = build_discriminator(param, embedding)\n",
        "\n",
        "    if param[\"number_of_gpus\"] > 1:\n",
        "        # models[\"combined_classifier\"] = multi_gpu_model(build_combined_classifier(inp, classifier), gpus = param[\"number_of_gpus\"])\n",
        "        models[\"combined_discriminator\"] = multi_gpu_model(build_combined_discriminator(inp, discriminator), gpus = param[\"number_of_gpus\"])\n",
        "        # models[\"combined_model\"] = multi_gpu_model(build_combined_model(inp, [classifier, discriminator]), gpus = param[\"number_of_gpus\"])\n",
        "    else:\n",
        "        # models[\"combined_classifier\"] = build_combined_classifier(inp, classifier)\n",
        "        models[\"combined_discriminator\"] = build_combined_discriminator(inp, discriminator)\n",
        "        # models[\"combined_model\"] = build_combined_model(inp, [classifier, discriminator])\n",
        "\n",
        "    # models[\"combined_classifier\"].compile(optimizer = opt_classifier(param), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    models[\"combined_discriminator\"].compile(optimizer = opt_discriminator(param), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "    # models[\"combined_model\"].compile(optimizer = opt_combined(param), loss = {'class_act_last': 'categorical_crossentropy', 'dis_act_last': \\\n",
        "    #     'binary_crossentropy'}, loss_weights = {'class_act_last': param[\"class_loss_weight\"], 'dis_act_last': param[\"dis_loss_weight\"]}, metrics = ['accuracy'])\n",
        "\n",
        "    Xs, ys = param[\"source_data\"], param[\"source_label\"]\n",
        "    Xt, yt = param[\"target_data\"], param[\"target_label\"]\n",
        "\n",
        "    # Source domain is represented by label 0 and Target by 1\n",
        "    ys_adv = np.array(([0.] * ys.shape[0]))\n",
        "    yt_adv = np.array(([1.] * yt.shape[0]))\n",
        "\n",
        "    y_advb_1 = np.array(([1] * param[\"batch_size\"] + [0] * param[\"batch_size\"])) # For gradient reversal\n",
        "    y_advb_2 = np.array(([0] * param[\"batch_size\"] + [1] * param[\"batch_size\"]))\n",
        "    weight_class = np.array(([1] * param[\"batch_size\"] + [0] * param[\"batch_size\"]))\n",
        "    weight_adv = np.ones((param[\"batch_size\"] * 2,))\n",
        "    S_batches = batch_generator([Xs, ys], param[\"batch_size\"])\n",
        "    T_batches = batch_generator([Xt, np.zeros(shape = (len(Xt),))], param[\"batch_size\"])\n",
        "\n",
        "    param[\"target_accuracy\"] = 0\n",
        "\n",
        "    optim = {}\n",
        "    optim[\"iter\"] = 0\n",
        "    optim[\"acc\"] = \"\"\n",
        "    optim[\"labels\"] = np.array(Xt.shape[0],)\n",
        "    gap_last_snap = 0\n",
        "\n",
        "    for i in range(param[\"num_iterations\"]):        \n",
        "        Xsb, ysb = next(S_batches)\n",
        "        Xtb, ytb = next(T_batches)\n",
        "        X_adv = np.concatenate([Xsb, Xtb])\n",
        "        y_class = np.concatenate([ysb, np.zeros_like(ysb)])\n",
        "\n",
        "        adv_weights = []\n",
        "        for layer in models[\"combined_model\"].layers_yerus:\n",
        "            if (layer.name.startswith(\"dis_\")):\n",
        "                adv_weights.append(layer.get_weights())\n",
        "          \n",
        "        stats1 = models[\"combined_model\"].train_on_batch(X_adv, [y_class, y_advb_1],\\\n",
        "                                sample_weight=[weight_class, weight_adv])            \n",
        "        k = 0\n",
        "        for layer in models[\"combined_model\"].layers:\n",
        "            if (layer.name.startswith(\"dis_\")):                    \n",
        "                layer.set_weights(adv_weights[k])\n",
        "                k += 1\n",
        "\n",
        "        class_weights = []        \n",
        "        for layer in models[\"combined_model\"].layers:\n",
        "            if (not layer.name.startswith(\"dis_\")):\n",
        "                class_weights.append(layer.get_weights())  \n",
        "\n",
        "        stats2 = models[\"combined_discriminator\"].train_on_batch(X_adv, [y_advb_2])\n",
        "\n",
        "        k = 0\n",
        "        for layer in models[\"combined_model\"].layers:\n",
        "            if (not layer.name.startswith(\"dis_\")):\n",
        "                layer.set_weights(class_weights[k])\n",
        "                k += 1\n",
        "\n",
        "        if ((i + 1) % param[\"test_interval\"] == 0):\n",
        "            ys_pred = models[\"combined_classifier\"].predict(Xs)\n",
        "            yt_pred = models[\"combined_classifier\"].predict(Xt)\n",
        "            ys_adv_pred = models[\"combined_discriminator\"].predict(Xs)\n",
        "            yt_adv_pred = models[\"combined_discriminator\"].predict(Xt)\n",
        "\n",
        "            source_accuracy = accuracy_score(ys.argmax(1), ys_pred.argmax(1))              \n",
        "            target_accuracy = accuracy_score(yt.argmax(1), yt_pred.argmax(1))\n",
        "            source_domain_accuracy = accuracy_score(ys_adv, np.round(ys_adv_pred))              \n",
        "            target_domain_accuracy = accuracy_score(yt_adv, np.round(yt_adv_pred))\n",
        "            print(source_domain_accuracy)\n",
        "            print(target_domain_accuracy)\n",
        "            log_str = \"iter: {:05d}: \\nLABEL CLASSIFICATION: source_accuracy: {:.5f}, target_accuracy: {:.5f}\\\n",
        "                    \\nDOMAIN DISCRIMINATION: source_domain_accuracy: {:.5f}, target_domain_accuracy: {:.5f} \\n\"\\\n",
        "                                                         .format(i, source_accuracy*100, target_accuracy*100,\n",
        "                                                      source_domain_accuracy*100, target_domain_accuracy*100)\n",
        "            print(log_str)\n",
        "\n",
        "            if param[\"target_accuracy\"] < target_accuracy:              \n",
        "                optim[\"iter\"] = i\n",
        "                optim[\"acc\"] = log_str\n",
        "                # optim[\"labels\"] = ys_pred.argmax(1)\n",
        "\n",
        "                if (gap_last_snap >= param[\"snapshot_interval\"]):\n",
        "                    gap_last_snap = 0\n",
        "                    np.save(os.path.join(param[\"output_path\"],\"yPred_{}\".format(optim[\"iter\"])), optim[\"labels\"])\n",
        "                    open(os.path.join(param[\"output_path\"], \"acc_{}.txt\".format(optim[\"iter\"])), \"w\").write(optim[\"acc\"])\n",
        "                    models[\"combined_classifier\"].save(os.path.join(param[\"output_path\"],\"iter_{:05d}_model.h5\".format(i)))\n",
        "        gap_last_snap = gap_last_snap + 1;\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Read parameter values from the console\n",
        "    parser = argparse.ArgumentParser(description = 'Domain Adaptation')\n",
        "    parser.add_argument('--number_of_gpus', type = int, nargs = '?', default = '1', help = \"Number of gpus to run\")\n",
        "    parser.add_argument('--network_name', type = str, default = 'ResNet50', help = \"Name of the feature extractor network\")\n",
        "    parser.add_argument('--dataset_name', type = str, default = 'Office', help = \"Name of the source dataset\")\n",
        "    parser.add_argument('--dropout_classifier', type = float, default = 0.25, help = \"Dropout ratio for classifier\")\n",
        "    parser.add_argument('--dropout_discriminator', type = float, default = 0.25, help = \"Dropout ratio for discriminator\")    \n",
        "    parser.add_argument('--source_path', type = str, default = 'amazon_10_list.txt', help = \"Path to source dataset\")\n",
        "    parser.add_argument('--target_path', type = str, default = 'webcam_10_list.txt', help = \"Path to target dataset\")\n",
        "    parser.add_argument('--lr_classifier', type = float, default = 0.0001, help = \"Learning rate for classifier model\")\n",
        "    parser.add_argument('--b1_classifier', type = float, default = 0.9, help = \"Exponential decay rate of first moment \\\n",
        "                                                                                             for classifier model optimizer\")\n",
        "    parser.add_argument('--b2_classifier', type = float, default = 0.999, help = \"Exponential decay rate of second moment \\\n",
        "                                                                                            for classifier model optimizer\")\n",
        "    parser.add_argument('--lr_discriminator', type = float, default = 0.00001, help = \"Learning rate for discriminator model\")\n",
        "    parser.add_argument('--b1_discriminator', type = float, default = 0.9, help = \"Exponential decay rate of first moment \\\n",
        "                                                                                             for discriminator model optimizer\")\n",
        "    parser.add_argument('--b2_discriminator', type = float, default = 0.999, help = \"Exponential decay rate of second moment \\\n",
        "                                                                                            for discriminator model optimizer\")\n",
        "    parser.add_argument('--lr_combined', type = float, default = 0.00001, help = \"Learning rate for combined model\")\n",
        "    parser.add_argument('--b1_combined', type = float, default = 0.9, help = \"Exponential decay rate of first moment \\\n",
        "                                                                                             for combined model optimizer\")\n",
        "    parser.add_argument('--b2_combined', type = float, default = 0.999, help = \"Exponential decay rate of second moment \\\n",
        "                                                                                            for combined model optimizer\")\n",
        "    parser.add_argument('--classifier_loss_weight', type = float, default = 1, help = \"Classifier loss weight\")\n",
        "    parser.add_argument('--discriminator_loss_weight', type = float, default = 4, help = \"Discriminator loss weight\")\n",
        "    parser.add_argument('--batch_size', type = int, default = 32, help = \"Batch size for training\")\n",
        "    parser.add_argument('--test_interval', type = int, default = 3, help = \"Gap between two successive test phases\")\n",
        "    parser.add_argument('--num_iterations', type = int, default = 12000, help = \"Number of iterations\")\n",
        "    parser.add_argument('--snapshot_interval', type = int, default = 500, help = \"Minimum gap between saving outputs\")\n",
        "    parser.add_argument('--output_dir', type = str, default = 'Models', help = \"Directory for saving outputs\")\n",
        "    # args = parser.parse_args()\n",
        "\n",
        "    # Set GPU device\n",
        "    # os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(list(np.arange(args.number_of_gpus))).strip('[]')\n",
        "\n",
        "    # Initialize parameters\n",
        "    param = {}\n",
        "    param[\"number_of_gpus\"] = 1\n",
        "    param[\"network_name\"] = 'ResNet50'\n",
        "    param[\"inp_dims\"] = [224, 224, 3]\n",
        "    param[\"num_iterations\"] = 12000\n",
        "    param[\"lr_classifier\"] = 0.0001\n",
        "    param[\"b1_classifier\"] = 0.9\n",
        "    param[\"b2_classifier\"] = 0.999    \n",
        "    param[\"lr_discriminator\"] = 0.00001\n",
        "    param[\"b1_discriminator\"] =  0.9\n",
        "    param[\"b2_discriminator\"] = 0.999\n",
        "    param[\"lr_combined\"] = 0.00001\n",
        "    param[\"b1_combined\"] =  0.9\n",
        "    param[\"b2_combined\"] =  0.999       \n",
        "    param[\"batch_size\"] = int(32/2)\n",
        "    param[\"class_loss_weight\"] = 1\n",
        "    param[\"dis_loss_weight\"] = 4    \n",
        "    param[\"drop_classifier\"] = 0.25\n",
        "    param[\"drop_discriminator\"] = 0.25\n",
        "    param[\"test_interval\"] = 3\n",
        "    param[\"source_path\"] = 'drive/My Drive/project_data/your_file.txt'\n",
        "    param[\"target_path\"] = 'drive/My Drive/project_data/your_file_shelly.txt' \n",
        "    param[\"snapshot_interval\"] = 500\n",
        "    param[\"output_path\"] = os.path.join(\"Snapshot\", 'Models')\n",
        "\n",
        "    # Create directory for saving models and log files\n",
        "    # if not os.path.exists(param[\"output_path\"]):\n",
        "    #     os.mkdir(param[\"output_path\"])\n",
        "    \n",
        "    # Load source and target data\n",
        "    param[\"source_data\"], param[\"source_label\"] = data_loader(param[\"source_path\"], param[\"inp_dims\"])\n",
        "    param[\"target_data\"], param[\"target_label\"] = data_loader(param[\"target_path\"], param[\"inp_dims\"])\n",
        "\n",
        "    # Encode labels into one-hot format\n",
        "    param[\"source_label\"], param[\"target_label\"] = one_hot_encoding(param)\n",
        "\n",
        "    # Train data\n",
        "    train(param)\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive/My Drive/project_data/﻿IMG_20180915_155413.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-7dd0cab275d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0;31m# Load source and target data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m     \u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"source_data\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"source_label\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"source_path\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"inp_dims\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m     \u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"target_data\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"target_label\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"target_path\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"inp_dims\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-53-7dd0cab275d3>\u001b[0m in \u001b[0;36mdata_loader\u001b[0;34m(filepath, inp_dims)\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0;31m# print('drive/My Drive/project_data/'+token[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"drive/My Drive/project_data/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_dims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp_dims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mANTIALIAS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-53-7dd0cab275d3>\u001b[0m in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# Return the RGB variant of input image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'drive/My Drive/project_data/\\ufeffIMG_20180915_155413.jpg'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8pb9VyIqh_q",
        "colab_type": "text"
      },
      "source": [
        "# Traib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBL2_iTDqmX2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(param):\n",
        "    models = {}\n",
        "    inp = Input(shape = (param[\"inp_dims\"]))\n",
        "    embedding = build_embedding(param, inp)\n",
        "    \n",
        "    discriminator = build_discriminator(param, embedding)\n",
        "    models[\"combined_discriminator\"] = build_combined_discriminator(inp, discriminator)     \n",
        "    models[\"combined_discriminator\"].compile(optimizer = opt_discriminator(param), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "   \n",
        "    Xs, ys = param[\"source_data\"], param[\"source_label\"]\n",
        "    Xt, yt = param[\"target_data\"], param[\"target_label\"]\n",
        "\n",
        "    # Source domain is represented by label 0 and Target by 1\n",
        "    ys_adv = np.array(([0.] * ys.shape[0]))\n",
        "    yt_adv = np.array(([1.] * yt.shape[0]))\n",
        "\n",
        "    y_advb_1 = np.array(([1] * param[\"batch_size\"] + [0] * param[\"batch_size\"])) # For gradient reversal\n",
        "    y_advb_2 = np.array(([0] * param[\"batch_size\"] + [1] * param[\"batch_size\"]))\n",
        "    weight_class = np.array(([1] * param[\"batch_size\"] + [0] * param[\"batch_size\"]))\n",
        "    weight_adv = np.ones((param[\"batch_size\"] * 2,))\n",
        "    S_batches = batch_generator([Xs, ys], param[\"batch_size\"])\n",
        "    T_batches = batch_generator([Xt, np.zeros(shape = (len(Xt),))], param[\"batch_size\"])\n",
        "\n",
        "    param[\"target_accuracy\"] = 0\n",
        "\n",
        "    optim = {}\n",
        "    optim[\"iter\"] = 0\n",
        "    optim[\"acc\"] = \"\"\n",
        "    optim[\"labels\"] = np.array(Xt.shape[0],)\n",
        "    gap_last_snap = 0\n",
        "\n",
        "    for i in range(param[\"num_iterations\"]):        \n",
        "        Xsb, ysb = next(S_batches)\n",
        "        Xtb, ytb = next(T_batches)\n",
        "        X_adv = np.concatenate([Xsb, Xtb])\n",
        "        y_class = np.concatenate([ysb, np.zeros_like(ysb)])\n",
        "\n",
        "        adv_weights = []  \n",
        "\n",
        "        stats2 = models[\"combined_discriminator\"].train_on_batch(X_adv, [y_advb_2])\n",
        "\n",
        "        if ((i + 1) % param[\"test_interval\"] == 0):\n",
        "\n",
        "            ys_adv_pred = models[\"combined_discriminator\"].predict(Xs)\n",
        "            yt_adv_pred = models[\"combined_discriminator\"].predict(Xt)\n",
        "            source_domain_accuracy = accuracy_score(ys_adv, np.round(ys_adv_pred))              \n",
        "            target_domain_accuracy = accuracy_score(yt_adv, np.round(yt_adv_pred))\n",
        "            print(source_domain_accuracy)\n",
        "            print(target_domain_accuracy)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2tAkuZEvWDO",
        "colab_type": "code",
        "outputId": "b5ed4d07-5ec0-466f-d852-e8b77bdd4c2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "with open('drive/My Drive/project_data/your_file.txt','r') as fp:\n",
        "        for line in fp:\n",
        "          print(line)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "﻿IMG_20180915_155413.jpg 1\n",
            "\n",
            "IMG_20180817_103847.jpg 1\n",
            "\n",
            "20190305_231251_HDR.jpg 1\n",
            "\n",
            "IMG_20180404_142858.jpg 1\n",
            "\n",
            "IMG_20180401_174227.jpg 1\n",
            "\n",
            "IMG_20180401_174244.jpg 1\n",
            "\n",
            "IMG_20180401_174256.jpg 1\n",
            "\n",
            "IMG_20180403_173010.jpg 1\n",
            "\n",
            "IMG_20180403_173014.jpg 1\n",
            "\n",
            "20170916_165947.jpg 1\n",
            "\n",
            "20171010_145000.jpg 1\n",
            "\n",
            "IMG_20171114_172941.jpg 1\n",
            "\n",
            "IMG_20180222_161547.jpg 1\n",
            "\n",
            "IMG_20180330_233831.jpg 1\n",
            "\n",
            "IMG_20180330_233904.jpg 1\n",
            "\n",
            "IMG_20180403_172954.jpg 1\n",
            "\n",
            "IMG_20180909_210126.jpg 1\n",
            "\n",
            "IMG_20180909_210149.jpg 1\n",
            "\n",
            "IMG_20180428_172455.jpg 1\n",
            "\n",
            "IMG_20180817_104012.jpg 1\n",
            "\n",
            "IMG_20180817_104013.jpg 1\n",
            "\n",
            "IMG_20180817_104014.jpg 1\n",
            "\n",
            "IMG_20180404_174732.jpg 1\n",
            "\n",
            "20190305_231227_HDR.jpg 1\n",
            "\n",
            "20190116_205737.jpg 1\n",
            "\n",
            "20190116_205743.jpg 1\n",
            "\n",
            "20190225_200713.jpg 1\n",
            "\n",
            "20190101_011516.jpg 1\n",
            "\n",
            "IMG_20181016_232643.jpg 1\n",
            "\n",
            "IMG_20180428_172801.jpg 1\n",
            "\n",
            "IMG_20181016_232643.jpg 1\n",
            "\n",
            "20190903_180900.jpg 1\n",
            "\n",
            "20190903_180904.jpg 1\n",
            "\n",
            "20190504_145247.jpg 1\n",
            "\n",
            "IMG_20180613_124912.jpg 1\n",
            "\n",
            "IMG_20180715_123217.jpg 1\n",
            "\n",
            "IMG_20180724_121256.jpg 1\n",
            "\n",
            "IMG_20180915_155404.jpg 1\n",
            "\n",
            "IMG_20180909_210420.jpg 1\n",
            "\n",
            "IMG_20180909_210736.jpg 1\n",
            "\n",
            "20190305_231230_HDR.jpg 1\n",
            "\n",
            "IMG_20180922_150334.jpg 0\n",
            "\n",
            "IMG_20180817_103635.jpg 0\n",
            "\n",
            "IMG_20181026_141156.jpg 0\n",
            "\n",
            "IMG_20180401_174342.jpg 0\n",
            "\n",
            "IMG_20180401_174350.jpg 0\n",
            "\n",
            "IMG_20180810_142624.jpg 0\n",
            "\n",
            "IMG_20180222_161741_1.jpg 0\n",
            "\n",
            "IMG_20180222_161745.jpg 0\n",
            "\n",
            "IMG_20180321_094112.jpg 0\n",
            "\n",
            "IMG_20180321_094114.jpg 0\n",
            "\n",
            "20190201_224518.jpg 0\n",
            "\n",
            "20190201_224615.jpg 0\n",
            "\n",
            "20190201_235008.jpg 0\n",
            "\n",
            "IMG_20180909_210034.jpg 0\n",
            "\n",
            "IMG_20180909_210139.jpg 0\n",
            "\n",
            "IMG_20180909_210208.jpg 0\n",
            "\n",
            "IMG_20180321_094115_1.jpg 0\n",
            "\n",
            "IMG_20180401_174215.jpg 0\n",
            "\n",
            "20190321_192201.jpg 0\n",
            "\n",
            "20190321_192246.jpg 0\n",
            "\n",
            "20190322_120228.jpg 0\n",
            "\n",
            "20190325_123824_HDR.jpg 0\n",
            "\n",
            "20190325_123833_HDR.jpg 0\n",
            "\n",
            "20190407_165320.jpg 0\n",
            "\n",
            "20190407_165341.jpg 0\n",
            "\n",
            "20190407_165552.jpg 0\n",
            "\n",
            "20190423_144630.jpg 0\n",
            "\n",
            "IMG_20180428_172324.jpg 0\n",
            "\n",
            "IMG_20181001_013824.jpg 0\n",
            "\n",
            "IMG_20181026_142133.jpg 0\n",
            "\n",
            "IMG_20181026_142138.jpg 0\n",
            "\n",
            "20181127_135044.jpg 0\n",
            "\n",
            "20181201_114228.jpg 0\n",
            "\n",
            "20181202_150111.jpg 0\n",
            "\n",
            "20181214_143138.jpg 0\n",
            "\n",
            "20181214_143148.jpg 0\n",
            "\n",
            "20190216_141515.jpg 0\n",
            "\n",
            "20190216_141531.jpg 0\n",
            "\n",
            "20190222_135810.jpg 0\n",
            "\n",
            "20190225_200749.jpg 0\n",
            "\n",
            "IMG_20181010_175117.jpg 0\n",
            "\n",
            "IMG_20181010_175119.jpg 0\n",
            "\n",
            "IMG_20181010_175418.jpg 0\n",
            "\n",
            "IMG_20181022_142712.jpg 0\n",
            "\n",
            "20190101_011503.jpg 0\n",
            "\n",
            "20190111_012134.jpg 0\n",
            "\n",
            "20190111_012156.jpg 0\n",
            "\n",
            "20190111_012159.jpg 0\n",
            "\n",
            "20190111_012203.jpg 0\n",
            "\n",
            "20190111_012205.jpg 0\n",
            "\n",
            "20190201_223209.jpg 0\n",
            "\n",
            "IMG-20131129-WA0002.jpg 0\n",
            "\n",
            "IMG-20131206-WA0003.jpg 0\n",
            "\n",
            "IMG_20180613_124909.jpg 0\n",
            "\n",
            "IMG_20180703_114515.jpg 0\n",
            "\n",
            "IMG_20180715_123216.jpg 0\n",
            "\n",
            "IMG_20180808_202704.jpg 0\n",
            "\n",
            "IMG_20180808_202814.jpg 0\n",
            "\n",
            "IMG_20180810_142336.jpg 0\n",
            "\n",
            "20181214_143214.jpg 0\n",
            "\n",
            "IMG_20181026_141202.jpg 0\n",
            "\n",
            "IMG_20181026_141401.jpg 0\n",
            "\n",
            "IMG_20181026_141632.jpg 0\n",
            "\n",
            "IMG_20181026_142131.jpg 0\n",
            "\n",
            "20190722_191244.jpg 0\n",
            "\n",
            "20190803_031054.jpg 0\n",
            "\n",
            "20190808_140636.jpg 0\n",
            "\n",
            "IMG_20180915_155401.jpg 0\n",
            "\n",
            "20181214_143208.jpg 0\n",
            "\n",
            "20181214_143210.jpg 0\n",
            "\n",
            "IMG_20180909_210414.jpg 0\n",
            "\n",
            "IMG_20180909_210416.jpg 0\n",
            "\n",
            "IMG_20180909_210426.jpg 0\n",
            "\n",
            "IMG_20180909_212827.jpg 0\n",
            "\n",
            "IMG_20180909_212838.jpg 0\n",
            "\n",
            "IMG_20180910_213629.jpg 0\n",
            "\n",
            "IMG_20180915_155355.jpg 0\n",
            "\n",
            "IMG_20180808_202_3704.jpg 0\n",
            "\n",
            "IMG_20180613_125854909.jpg 0\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqYXgaotqk_g",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bxcy4fLWqpgf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from keras.models import Model\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.layers import Input, Conv2D, MaxPool2D, Flatten, Dense\n",
        "from keras.layers import BatchNormalization, Activation, Dropout\n",
        "\n",
        "def build_embedding(param, inp):\n",
        "    network = eval(param[\"network_name\"])\n",
        "    base = network(weights = 'imagenet', include_top = False)\n",
        "    feat = base(inp)\n",
        "    flat = Flatten()(feat)\n",
        "    return flat\n",
        "\n",
        "def build_classifier(param, embedding):\n",
        "    dense1 = Dense(400, name = 'class_dense1')(embedding)\n",
        "    bn1 = BatchNormalization(name = 'class_bn1')(dense1)\n",
        "    act1 = Activation('relu', name = 'class_act1')(bn1)\n",
        "    drop2 = Dropout(param[\"drop_classifier\"], name = 'class_drop1')(act1)\n",
        "\n",
        "    dense2 = Dense(100, name = 'class_dense2')(drop2)\n",
        "    bn2 = BatchNormalization(name = 'class_bn2')(dense2)\n",
        "    act2 = Activation('relu', name = 'class_act2')(bn2)\n",
        "    drop2 = Dropout(param[\"drop_classifier\"], name = 'class_drop2')(act2)\n",
        "\n",
        "    densel = Dense(param[\"source_label\"].shape[1], name = 'class_dense_last')(drop2)\n",
        "    bnl = BatchNormalization(name = 'class_bn_last')(densel)\n",
        "    actl = Activation('softmax', name = 'class_act_last')(bnl)\n",
        "    return actl\n",
        "\n",
        "def build_discriminator(param, embedding):\n",
        "    dense1 = Dense(400, name = 'dis_dense1')(embedding)\n",
        "    bn1 = BatchNormalization(name='dis_bn1')(dense1)\n",
        "    act1 = Activation('relu', name = 'dis_act1')(bn1)\n",
        "    drop1 = Dropout(param[\"drop_discriminator\"], name = 'dis_drop1')(act1)\n",
        "\n",
        "    dense2 = Dense(100, name = 'dis_dense2')(drop1)\n",
        "    bn2 = BatchNormalization(name='dis_bn2')(dense2)\n",
        "    act2 = Activation('relu', name = 'dis_act2')(bn2)\n",
        "    drop2 = Dropout(param[\"drop_discriminator\"], name = 'dis_drop2')(act2)\n",
        "\n",
        "    densel = Dense(1, name = 'dis_dense_last')(drop2)\n",
        "    bnl = BatchNormalization(name = 'dis_bn_last')(densel)\n",
        "    actl = Activation('sigmoid', name = 'dis_act_last')(bnl)\n",
        "    return actl\n",
        "\n",
        "def build_combined_classifier(inp, classifier):\n",
        "    comb_model = Model(inputs = inp, outputs = [classifier])\n",
        "    return comb_model\n",
        "\n",
        "def build_combined_discriminator(inp, discriminator):\n",
        "    comb_model = Model(inputs = inp, outputs = [discriminator])\n",
        "    return comb_model\n",
        "\n",
        "def build_combined_model(inp, comb):\n",
        "    comb_model = Model(inputs = inp, outputs = comb)\n",
        "    return comb_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DrTIu1SqtIe",
        "colab_type": "text"
      },
      "source": [
        "# Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ve8K7kUmqu5W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "def opt_classifier(param):\n",
        "    return Adam(lr=param[\"lr_classifier\"], beta_1=param[\"b1_classifier\"], beta_2=param[\"b2_classifier\"])\n",
        "\n",
        "def opt_discriminator(param):\n",
        "    return Adam(lr=param[\"lr_discriminator\"], beta_1=param[\"b1_discriminator\"], beta_2=param[\"b2_discriminator\"])\n",
        "\n",
        "def opt_combined(param):\n",
        "    return Adam(lr=param[\"lr_combined\"], beta_1=param[\"b1_combined\"], beta_2=param[\"b2_combined\"])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHRxvLjYqwvG",
        "colab_type": "text"
      },
      "source": [
        "# Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxlgU5w6qyJO",
        "colab_type": "code",
        "outputId": "32076cc8-b400-4ef6-eb56-f9bf56e6e83b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}