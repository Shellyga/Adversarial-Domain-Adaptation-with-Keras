{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "new implementation adda.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shellyga/Adversarial-Domain-Adaptation-with-Keras/blob/master/new_implementation_adda.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tX9wzLSuurKf",
        "colab_type": "text"
      },
      "source": [
        "# Load images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6Aa99XjqDwK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "46bd999e-eb38-46ff-e1b4-5c6dcd7b4294"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvrNQ6NqkT1u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SEED = 7\n",
        "import os\n",
        "import sys\n",
        "import argparse\n",
        "import random\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from plotnine import *\n",
        "import pandas as pd\n",
        "                \n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from math import ceil\n",
        "from sklearn.utils import shuffle as skshuffle\n",
        "\n",
        "from imutils import paths\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# os.environ['PYTHONHASHSEED']=str(SEED)\n",
        "# np.random.seed(SEED)\n",
        "# set_random_seed(SEED)\n",
        "# random.seed(SEED)\n",
        "\n",
        "from PIL import Image\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Input\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import multi_gpu_model\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pickle\n",
        "\n",
        "NUM_CLASSES = 0\n",
        "\n",
        "\n",
        "def pil_loader(path):\n",
        "    # print(path)\n",
        "    # Return the RGB variant of input image\n",
        "    with open(path, 'rb') as f:\n",
        "      with Image.open(f) as img:\n",
        "        return img.convert('RGB')\n",
        "\n",
        "def one_hot_encoding(param,labels):\n",
        "    lb = LabelEncoder()\n",
        "    fit_labels  = lb.fit_transform(labels)\n",
        "    param[\"number_of_classe\"] = len(lb.classes_) \n",
        "    labels = to_categorical(fit_labels)\n",
        "    f = open('drive/My Drive/pro_data/result_vgg/labels',\"wb\")\n",
        "    f.write(pickle.dumps(lb))\n",
        "    f.close()\n",
        "    return labels\n",
        "\n",
        "            \n",
        "def data_loader(filepath, inp_dims):\n",
        "    # Load images and corresponding labels from the text file, stack them in numpy arrays and return\n",
        "    # if not os.path.isfile(filepath):\n",
        "    #     print(\"File path {} does not exist. Exiting...\".format(filepath))\n",
        "        # sys.exit() \n",
        "    img = []\n",
        "    label = []\n",
        "    detector = dlib.get_frontal_face_detector()\n",
        "    predictor = \"drive/My Drive/pro_data/shape_predictor_5_face_landmarks.dat\"\n",
        "    # grab the image paths\n",
        "    imagePaths = sorted(list(paths.list_images(filepath)))\n",
        "    # print(imagePaths)\n",
        "    # loop over the input images\n",
        "    for imagePath in imagePaths:\n",
        "        # extract the class label from the image path and update the\n",
        "        # labels list\n",
        "        l = imagePath.split(os.path.sep)[-2]\n",
        "        label.append(l)\n",
        "        i = pil_loader(imagePath)\n",
        "\n",
        "        i = i.resize((inp_dims[0], inp_dims[1]), Image.ANTIALIAS)\n",
        "        frame_1 = align_and_crop(detector, np.array(i), predictor)[0]\n",
        "        frame_1 = cv2.resize(frame_1,(inp_dims[0], inp_dims[1]))\n",
        "        img.append(frame_1)\n",
        "    plt.imshow(i)\n",
        "    plt.imshow(frame_1)\n",
        "    plt.show()\n",
        "    img, label = skshuffle(img, label)\n",
        "    img = np.array(img)\n",
        "    label = np.array(label)\n",
        "    return img, label\n",
        "\n",
        "def get_dataset(param,path):\n",
        "      print(\"[INFO] loading images...\")\n",
        "      # Load source and target data\n",
        "      X,y = data_loader(path, [224,224,3])\n",
        "      print(\"images loaded\")\n",
        "      X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "      # Encode labels into one-hot format\n",
        "      print(\"[INFO] Encode labels into one-hot format\")\n",
        "      y_train = one_hot_encoding(param,y_train)\n",
        "      y_test = one_hot_encoding(param,y_test)\n",
        "      return (X_train, y_train), (X_test, y_test)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO1_9wE_pnyE",
        "colab_type": "text"
      },
      "source": [
        "# Crop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWjz0C4Spp5s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import dlib\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import cv2\n",
        "import glob\n",
        "\n",
        "\n",
        "def align_and_crop(detector, im_to_align, predictor_path):\n",
        "    '''\n",
        "    simply aligns the photo (using the detector to identify the eyes) and crops the face.\n",
        "    :param im_to_align: an address of an image\n",
        "    '''\n",
        "\n",
        "    # a shape predictor to find face landmarks so we can precisely localize the face\n",
        "    sp = dlib.shape_predictor(predictor_path)\n",
        "\n",
        "    # Ask the detector to find the bounding boxes of each face. The 1 in the\n",
        "    # second argument indicates that we should upsample the image 1 time.\n",
        "    try:\n",
        "        dets = detector(im_to_align, 1)\n",
        "    except RuntimeError:\n",
        "        return -1\n",
        "\n",
        "    num_faces = len(dets)\n",
        "    if num_faces == 0:\n",
        "        return im_to_align, False\n",
        "\n",
        "    # Find the 5 face landmarks we need to do the alignment.\n",
        "    faces = dlib.full_object_detections()\n",
        "    for detection in dets:\n",
        "        faces.append(sp(im_to_align, detection))\n",
        "\n",
        "    # get a single chip (aligned and cropped)\n",
        "    image = dlib.get_face_chip(im_to_align, faces[0])\n",
        "    # cv2.imshow(\"f\", image) show image for testing\n",
        "    return image, True"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Tmfa3J7RHIY",
        "colab_type": "text"
      },
      "source": [
        "# optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYr9mhNDRKUt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "def opt_classifier(param):\n",
        "    return Adam(lr=param[\"lr_classifier\"], beta_1=param[\"b1_classifier\"], beta_2=param[\"b2_classifier\"])\n",
        "\n",
        "def opt_discriminator(param):\n",
        "    return Adam(lr=param[\"lr_discriminator\"], beta_1=param[\"b1_discriminator\"], beta_2=param[\"b2_discriminator\"])\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enWnpRmFu2xn",
        "colab_type": "text"
      },
      "source": [
        "# ADDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtMj_BdtpGf4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "a33ec13a-6613-4e59-ede6-c3670027ad66"
      },
      "source": [
        "pip install keras_vggface"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras_vggface in /usr/local/lib/python3.6/dist-packages (0.6)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from keras_vggface) (7.0.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras_vggface) (2.4.3)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras_vggface) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras_vggface) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras_vggface) (1.18.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras_vggface) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras_vggface) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyAy4zQuS-Kw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "4e444031-9f4c-4bbe-e161-018649c6d50f"
      },
      "source": [
        "pip install keras_applications"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras_applications in /usr/local/lib/python3.6/dist-packages (1.0.8)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras_applications) (1.18.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras_applications) (2.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras_applications) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7r2jSUrZ6SW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
        "from keras.layers import BatchNormalization, Activation\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "from keras.models import Sequential, Model, clone_model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "import keras\n",
        "from keras.utils import np_utils\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "# from datasets import get_dataset\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "import argparse\n",
        "from keras_vggface.vggface import VGGFace"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9nhhLN-LvWy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def define_source_encoder():\n",
        "\n",
        "        inp = Input(shape= param[\"inp_dims\"])\n",
        "        network = eval('VGGFace')\n",
        "        base = network(weights = 'vggface', include_top = False)\n",
        "        param[\"source_encoder\"] = Model(inp,base(inp))\n",
        "\n",
        "def define_target_encoder():\n",
        "       param[\"target_encoder\"] = clone_model(param[\"source_encoder\"])\n",
        "\n",
        "def get_source_classifier(model):\n",
        "        \n",
        "    x = Flatten()(model.output)\n",
        "    dense1 = Dense(400, name = 'class_dense1')(x)\n",
        "    bn1 = BatchNormalization(name = 'class_bn1')(dense1)\n",
        "    act1 = Activation('relu', name = 'class_act1')(bn1)\n",
        "    drop2 = Dropout(param[\"drop_classifier\"], name = 'class_drop1')(act1)\n",
        "\n",
        "    dense2 = Dense(100, name = 'class_dense2')(drop2)\n",
        "    bn2 = BatchNormalization(name = 'class_bn2')(dense2)\n",
        "    act2 = Activation('relu', name = 'class_act2')(bn2)\n",
        "    drop2 = Dropout(param[\"drop_classifier\"], name = 'class_drop2')(act2)\n",
        "    densel = Dense(param[\"number_of_classe\"], name = 'class_dense_last')(drop2)\n",
        "    # densel = Dense(param[\"number_of_classe\"], name = 'class_dense_last')(x)\n",
        "    bnl = BatchNormalization(name = 'class_bn_last')(densel)\n",
        "    actl = Activation('softmax', name = 'class_act_last')(bnl)\n",
        "        \n",
        "    source_classifier_model = Model(inputs=(model.input), outputs=(actl))\n",
        "        \n",
        "    return source_classifier_model\n",
        "\n",
        "def define_discriminator(shape):\n",
        "        \n",
        "    inp = Input(shape=shape)\n",
        "    x = Flatten()(inp)\n",
        "    dense1 = Dense(400, name = 'dis_dense1')(x)\n",
        "    bn1 = BatchNormalization(name='dis_bn1')(dense1)\n",
        "    act1 = Activation('relu', name = 'dis_act1')(bn1)\n",
        "    drop1 = Dropout(param[\"drop_discriminator\"], name = 'dis_drop1')(act1)\n",
        "\n",
        "    dense2 = Dense(100, name = 'dis_dense2')(drop1)\n",
        "    bn2 = BatchNormalization(name='dis_bn2')(dense2)\n",
        "    act2 = Activation('relu', name = 'dis_act2')(bn2)\n",
        "    drop2 = Dropout(param[\"drop_discriminator\"], name = 'dis_drop2')(act2)\n",
        "\n",
        "    densel = Dense(1, name = 'dis_dense_last')(drop2)\n",
        "    # densel = Dense(1, name = 'dis_dense_last')(x)\n",
        "    bnl = BatchNormalization(name = 'dis_bn_last')(densel)\n",
        "    actl = Activation('sigmoid', name = 'dis_act_last')(bnl)\n",
        "    param[\"discriminator_model\"] = Model(inputs=(inp), outputs=(actl), name='discriminator')\n",
        "\n",
        "def get_discriminator(model):    \n",
        "    disc = Model(inputs=(model.input), outputs=(param[\"discriminator_model\"](model.output)))\n",
        "    return disc\n",
        "\n",
        "  "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1fjt31dOGuK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_source_model(param, epochs=30, batch_size=128, save_interval=1, start_epoch=0):\n",
        "        checkpoint = ModelCheckpoint(\"drive/My Drive/pro_data/pro_book_res/source_model.h5\", monitor='val_accuracy', verbose=1, \n",
        "                             save_best_only=True, save_weights_only=False, mode='auto')\n",
        "        early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=20, verbose=1, mode='auto')\n",
        "\n",
        "        (train_x, train_y), (test_x, test_y) = param[\"source_data_train\"], param[\"source_data_test\"]\n",
        "        datagen = ImageDataGenerator(data_format='channels_last', \n",
        "                                rescale=1./255, \n",
        "                                rotation_range=40, \n",
        "                                width_shift_range=0.2, \n",
        "                                height_shift_range=0.2)\n",
        "       \n",
        "        evalgen = ImageDataGenerator(data_format='channels_last', \n",
        "                                rescale=1./255)\n",
        "        \n",
        "        param[\"source_model\"].compile(optimizer = opt_classifier(param), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "        train_generator  = datagen.flow(train_x, train_y, batch_size=batch_size, shuffle=True)\n",
        "        # plt.imshow(train_generator.next()[0][0])\n",
        "        # plt.show()\n",
        "        param[\"source_model\"].fit_generator(train_generator ,\n",
        "                            steps_per_epoch=10, \n",
        "                            epochs=epochs, \n",
        "                            validation_data=evalgen.flow(test_x, test_y, batch_size=batch_size), \n",
        "                            initial_epoch=start_epoch,callbacks=[checkpoint,early])\n",
        "        \n",
        "        # param[\"source_model\"].save('drive/My Drive/pro_data/result_vgg/source_model_updated.h5')\n",
        "\n",
        "        y_pred = param[\"source_model\"].predict(test_x)\n",
        "        source_accuracy_test = accuracy_score(test_y.argmax(1), y_pred.argmax(1))              \n",
        "\n",
        "        print(\"source accuracy test\",source_accuracy_test)\n",
        "        print(\"Source Classifier matrix: \",metrics.confusion_matrix(test_y.argmax(1), y_pred.argmax(1)))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IB2gS_UpO2Uh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_target_discriminator(param, epochs=2, batch_size=128, save_interval=40, start_epoch=0, num_batches=120):   \n",
        "    \n",
        "        (source_x, _), (_,_) = param[\"source_data_train\"], param[\"source_data_test\"]\n",
        "        \n",
        "        src_datagen = ImageDataGenerator(data_format='channels_last', \n",
        "                                rescale=1./255, \n",
        "                                rotation_range=40, \n",
        "                                width_shift_range=0.2, \n",
        "                                height_shift_range=0.2)\n",
        "        \n",
        "        (target_x, _), (_,_) = param[\"target_data_train\"], param[\"target_data_test\"]\n",
        "        \n",
        "        tgt_datagen = ImageDataGenerator(data_format='channels_last', \n",
        "                                rescale=1./255, \n",
        "                                rotation_range=40, \n",
        "                                width_shift_range=0.2, \n",
        "                                height_shift_range=0.2)\n",
        "        \n",
        "        # define_source_encoder()\n",
        "        # define_target_encoder()\n",
        "        param[\"source_encoder\"].save_weights('drive/My Drive/pro_data/pro_book_res/encoder_s_weights.hdf5')\n",
        "        define_discriminator(param[\"source_encoder\"].output_shape[1:])\n",
        "        \n",
        "        param[\"source_dicriminator\"] = get_discriminator(param[\"source_encoder\"])\n",
        "        param[\"target_dicriminator\"]= get_discriminator(param[\"target_encoder\"])\n",
        "        param[\"target_dicriminator\"].compile(optimizer = opt_discriminator(param), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "        for layer in param[\"source_encoder\"].layers:\n",
        "            layer.trainable = False\n",
        "        \n",
        "        param[\"source_dicriminator\"].compile(optimizer = opt_discriminator(param), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "        \n",
        "        src_names = ['src_discriminator_loss', 'src_discriminator_acc']\n",
        "        tgt_names = ['tgt_discriminator_loss', 'tgt_discriminator_acc']\n",
        "        \n",
        "        for iteration in range(start_epoch, epochs):\n",
        "            \n",
        "            avg_loss, avg_acc, index = [0, 0], [0, 0], 0\n",
        "\n",
        "            for source,target in zip(src_datagen.flow(source_x, None, batch_size=batch_size), tgt_datagen.flow(target_x, None, batch_size=batch_size)):\n",
        "                # s_domain = np_utils.to_categorical(np.zeros(source.shape[0]), 1)\n",
        "                # t_domain =  np_utils.to_categorical(np.ones(target.shape[0]), 1)\n",
        "                s_domain = np.zeros(source.shape[0])\n",
        "                t_domain =  np.ones(target.shape[0])\n",
        "                l1, acc1 = param[\"source_dicriminator\"].train_on_batch(source,s_domain )\n",
        "                l2, acc2 = param[\"target_dicriminator\"].train_on_batch(target,t_domain)\n",
        "                index+=1\n",
        "                loss, acc = (l1+l2)/2, (acc1+acc2)/2\n",
        "                print (iteration+1,': ', index,'/', num_batches, '; Loss: %.4f'%loss, ' (', '%.4f'%l1, '%.4f'%l2, '); Accuracy: ', acc, ' (', '%.4f'%acc1, '%.4f'%acc2, ')')\n",
        "                avg_loss[0] += l1\n",
        "                avg_acc[0] += acc1\n",
        "                avg_loss[1] += l2\n",
        "                avg_acc[1] += acc2\n",
        "                if index%num_batches == 0:\n",
        "                    break\n",
        "            \n",
        "            \n",
        "                if index%save_interval==0:\n",
        "                  param[\"source_dicriminator\"].save_weights('drive/My Drive/pro_data/pro_book_res/discriminator_s_weights_%02d.hdf5'%index)\n",
        "                  param[\"target_dicriminator\"].save_weights('drive/My Drive/pro_data/pro_book_res/discriminator_t_weights_%02d.hdf5'%index)\n",
        "                  param[\"target_encoder\"].save_weights('drive/My Drive/pro_data/pro_book_res/encoder_t_weights_%02d.hdf5'%index)\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ci4r1ThjQbJw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval_source_classifier( param,  model,batch_size=128, domain='Source'):\n",
        "      \n",
        "        (train_x,_), (test_x, test_y) = param[\"target_data_train\"], param[\"target_data_test\"]\n",
        "        src_datagen = ImageDataGenerator(data_format='channels_last', \n",
        "                                        rescale=1./255)\n",
        "                      \n",
        "        model.compile(optimizer = opt_classifier(param), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "\n",
        "        scores = model.evaluate_generator(src_datagen.flow(test_x, test_y),10000)\n",
        "        print(' %s Classifier Test loss:%.5f'%( domain, scores[0]))\n",
        "        print(' %s Classifier Test accuracy:%.2f%%'%( domain, float(scores[1])*100))            \n",
        "            \n",
        "def eval_target_classifier(param):\n",
        "        \n",
        "        # param[\"target_encoder\"].summary()\n",
        "        # model = get_source_classifier(param[\"target_encoder\"])\n",
        "        model = param[\"source_model\"]\n",
        "        path_target_discriminator = 'drive/My Drive/pro_data/pro_book_res/discriminator_t_weights.hdf5'\n",
        "        model.load_weights(path_target_discriminator, by_name=True)\n",
        "        model.summary()\n",
        "        eval_source_classifier(param,  model, domain='Target')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NSeh8KIRkKD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "if __name__ == \"__main__\":\n",
        "    # Read parameter values from the console\n",
        "    parser = argparse.ArgumentParser(description = 'Domain Adaptation')\n",
        "    parser.add_argument('--number_of_gpus', type = int, nargs = '?', default = '1', help = \"Number of gpus to run\")\n",
        "    parser.add_argument('--network_name', type = str, default = 'ResNet50', help = \"Name of the feature extractor network\")\n",
        "    parser.add_argument('--dataset_name', type = str, default = 'Office', help = \"Name of the source dataset\")\n",
        "    parser.add_argument('--dropout_classifier', type = float, default = 0.25, help = \"Dropout ratio for classifier\")\n",
        "    parser.add_argument('--dropout_discriminator', type = float, default = 0.25, help = \"Dropout ratio for discriminator\")    \n",
        "    parser.add_argument('--source_path', type = str, default = 'amazon_10_list.txt', help = \"Path to source dataset\")\n",
        "    parser.add_argument('--target_path', type = str, default = 'webcam_10_list.txt', help = \"Path to target dataset\")\n",
        "    parser.add_argument('--lr_classifier', type = float, default = 0.0001, help = \"Learning rate for classifier model\")\n",
        "    parser.add_argument('--b1_classifier', type = float, default = 0.9, help = \"Exponential decay rate of first moment \\\n",
        "                                                                                             for classifier model optimizer\")\n",
        "    parser.add_argument('--b2_classifier', type = float, default = 0.999, help = \"Exponential decay rate of second moment \\\n",
        "                                                                                            for classifier model optimizer\")\n",
        "    parser.add_argument('--lr_discriminator', type = float, default = 0.00001, help = \"Learning rate for discriminator model\")\n",
        "    parser.add_argument('--b1_discriminator', type = float, default = 0.9, help = \"Exponential decay rate of first moment \\\n",
        "                                                                                             for discriminator model optimizer\")\n",
        "    parser.add_argument('--b2_discriminator', type = float, default = 0.999, help = \"Exponential decay rate of second moment \\\n",
        "                                                                                            for discriminator model optimizer\")\n",
        "    parser.add_argument('--lr_combined', type = float, default = 0.00001, help = \"Learning rate for combined model\")\n",
        "    parser.add_argument('--b1_combined', type = float, default = 0.9, help = \"Exponential decay rate of first moment \\\n",
        "                                                                                             for combined model optimizer\")\n",
        "    parser.add_argument('--b2_combined', type = float, default = 0.999, help = \"Exponential decay rate of second moment \\\n",
        "                                                                                            for combined model optimizer\")\n",
        "    parser.add_argument('--classifier_loss_weight', type = float, default = 1, help = \"Classifier loss weight\")\n",
        "    parser.add_argument('--discriminator_loss_weight', type = float, default = 4, help = \"Discriminator loss weight\")\n",
        "    parser.add_argument('--batch_size', type = int, default = 32, help = \"Batch size for training\")\n",
        "    parser.add_argument('--test_interval', type = int, default = 3, help = \"Gap between two successive test phases\")\n",
        "    parser.add_argument('--num_iterations', type = int, default = 120, help = \"Number of iterations\")\n",
        "    parser.add_argument('--snapshot_interval', type = int, default = 500, help = \"Minimum gap between saving outputs\")\n",
        "    parser.add_argument('--output_dir', type = str, default = 'Models', help = \"Directory for saving outputs\")\n",
        "    # args = parser.parse_args()\n",
        "\n",
        "    # Set GPU device\n",
        "    # os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(list(np.arange(args.number_of_gpus))).strip('[]')\n",
        "\n",
        "    # Initialize parameters\n",
        "    param = {}\n",
        "    param[\"number_of_gpus\"] = 1\n",
        "    # param[\"network_name\"] = 'ResNet50'\n",
        "    param[\"network_name\"] = 'VGGFace'\n",
        "    param[\"inp_dims\"] = [224, 224, 3]\n",
        "    param[\"num_iterations\"] = 1000\n",
        "    # param[\"num_iterations\"] = 500\n",
        "    param[\"lr_classifier\"] = 0.0001\n",
        "    param[\"b1_classifier\"] = 0.9\n",
        "    param[\"b2_classifier\"] = 0.999    \n",
        "    param[\"lr_discriminator\"] = 0.00001\n",
        "    param[\"b1_discriminator\"] =  0.9\n",
        "    param[\"b2_discriminator\"] = 0.999\n",
        "    param[\"lr_combined\"] = 0.00001\n",
        "    param[\"b1_combined\"] =  0.9\n",
        "    param[\"b2_combined\"] =  0.999       \n",
        "    # param[\"batch_size\"] = int(32)\n",
        "    param[\"batch_size\"] = int(32/2)\n",
        "    param[\"class_loss_weight\"] = 1\n",
        "    param[\"dis_loss_weight\"] = 4    \n",
        "    param[\"drop_classifier\"] = 0.25\n",
        "    param[\"drop_discriminator\"] = 0.25\n",
        "    param[\"test_interval\"] = 100\n",
        "    # param[\"source_path\"] = 'drive/My Drive/final_proj_dataset/data_file_shelly.txt'\n",
        "    # param[\"target_path\"] = 'drive/My Drive/final_proj_dataset/data_file_yerus.txt' \n",
        "    param[\"source_path\"] = 'drive/My Drive/pro_data/Student_source'\n",
        "    param[\"target_path\"] = 'drive/My Drive/pro_data/alyn_target' \n",
        "    param[\"snapshot_interval\"] = 500\n",
        "    # param[\"snapshot_interval\"] = 5\n",
        "    param[\"output_path\"] = 'drive/My Drive/pro_data/pro_book_res'\n",
        "    param[\"number_of_classe\"] = 0    \n",
        "    \n",
        "\n",
        "   "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_XSXhmJagR8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "4f1c3b9b-fd2b-494d-8406-82f0ed3e7631"
      },
      "source": [
        "    param[\"source_data_train\"], param[\"source_data_test\"] = get_dataset(param,param[\"source_path\"])\n",
        "    # param[\"target_data_train\"], param[\"target_data_test\"] = get_dataset(param,param[\"target_path\"])\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading images...\n",
            "images loaded\n",
            "[INFO] Encode labels into one-hot format\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOOF5O18WcXU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "23044ae4-5831-496a-c82b-68cb38b12cbe"
      },
      "source": [
        "print(\"[INFO] loading images...\")\n",
        "# Load source and target data\n",
        "X,y = data_loader(param[\"target_path\"], [224,224,3])\n",
        "print(\"images loaded\")\n",
        "X_test,y_test = data_loader('drive/My Drive/pro_data/testset', [224,224,3])\n",
        "print(\"[INFO] Encode labels into one-hot format\")\n",
        "y = one_hot_encoding(param,y)\n",
        "y_test = one_hot_encoding(param,y_test)\n",
        "param[\"target_data_train\"], param[\"target_data_test\"] =(X, y), (X_test, y_test)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading images...\n",
            "images loaded\n",
            "[INFO] Encode labels into one-hot format\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4ucDwvvLJmR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(X_test[0])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6-FM3qsgRg6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = one_hot_encoding(param,y)\n",
        "y_test = one_hot_encoding(param,y_test)\n",
        "param[\"target_data_train\"], param[\"target_data_test\"] =(X, y), (X_test, y_test)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWQO8s5CjSSu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "593b2d57-ee2b-42ac-f03a-13925931f5e2"
      },
      "source": [
        "print(\"number of images in target domain\",X.shape[0])\n",
        "print(\"number of images in target test domain\",X_test.shape[0])\n",
        "print(\"number of images in source domain\", param[\"source_data_train\"][0].shape[0])\n",
        "print(\"number of images in source test domain\", param[\"source_data_test\"][0].shape[0])\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of images in target domain 1440\n",
            "number of images in target test domain 40\n",
            "number of images in source domain 1159\n",
            "number of images in source test domain 290\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VfLO62x6uok",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c87ef2ba-dd65-4612-8b62-01a0b0cb2ca5"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "define_source_encoder()\n",
        "define_target_encoder()\n",
        "param[\"source_model\"] = get_source_classifier(param[\"source_encoder\"])\n",
        "train_source_model(param)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-9-014bc1a3f203>:24: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/30\n",
            " 2/10 [=====>........................] - ETA: 6s - loss: 1.2845 - accuracy: 0.3477WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4230s vs `on_train_batch_end` time: 1.0918s). Check your callbacks.\n",
            "10/10 [==============================] - ETA: 0s - loss: 1.0921 - accuracy: 0.4737\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.62759, saving model to drive/My Drive/pro_data/pro_book_res/source_model.h5\n",
            "10/10 [==============================] - 21s 2s/step - loss: 1.0921 - accuracy: 0.4737 - val_loss: 1.0211 - val_accuracy: 0.6276\n",
            "Epoch 2/30\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7959 - accuracy: 0.6419\n",
            "Epoch 00002: val_accuracy improved from 0.62759 to 0.71379, saving model to drive/My Drive/pro_data/pro_book_res/source_model.h5\n",
            "10/10 [==============================] - 20s 2s/step - loss: 0.7959 - accuracy: 0.6419 - val_loss: 0.9648 - val_accuracy: 0.7138\n",
            "Epoch 3/30\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6674 - accuracy: 0.7204\n",
            "Epoch 00003: val_accuracy improved from 0.71379 to 0.82759, saving model to drive/My Drive/pro_data/pro_book_res/source_model.h5\n",
            "10/10 [==============================] - 20s 2s/step - loss: 0.6674 - accuracy: 0.7204 - val_loss: 0.9268 - val_accuracy: 0.8276\n",
            "Epoch 4/30\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5963 - accuracy: 0.7834\n",
            "Epoch 00004: val_accuracy improved from 0.82759 to 0.83793, saving model to drive/My Drive/pro_data/pro_book_res/source_model.h5\n",
            "10/10 [==============================] - 20s 2s/step - loss: 0.5963 - accuracy: 0.7834 - val_loss: 0.9342 - val_accuracy: 0.8379\n",
            "Epoch 5/30\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5628 - accuracy: 0.8016\n",
            "Epoch 00005: val_accuracy did not improve from 0.83793\n",
            "10/10 [==============================] - 18s 2s/step - loss: 0.5628 - accuracy: 0.8016 - val_loss: 0.8899 - val_accuracy: 0.7724\n",
            "Epoch 6/30\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5254 - accuracy: 0.8361\n",
            "Epoch 00006: val_accuracy improved from 0.83793 to 0.88621, saving model to drive/My Drive/pro_data/pro_book_res/source_model.h5\n",
            "10/10 [==============================] - 20s 2s/step - loss: 0.5254 - accuracy: 0.8361 - val_loss: 0.8704 - val_accuracy: 0.8862\n",
            "Epoch 7/30\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4421 - accuracy: 0.8913\n",
            "Epoch 00007: val_accuracy improved from 0.88621 to 0.88966, saving model to drive/My Drive/pro_data/pro_book_res/source_model.h5\n",
            "10/10 [==============================] - 20s 2s/step - loss: 0.4421 - accuracy: 0.8913 - val_loss: 0.8187 - val_accuracy: 0.8897\n",
            "Epoch 8/30\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4135 - accuracy: 0.9025\n",
            "Epoch 00008: val_accuracy improved from 0.88966 to 0.90345, saving model to drive/My Drive/pro_data/pro_book_res/source_model.h5\n",
            "10/10 [==============================] - 21s 2s/step - loss: 0.4135 - accuracy: 0.9025 - val_loss: 0.7788 - val_accuracy: 0.9034\n",
            "Epoch 9/30\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4073 - accuracy: 0.8965\n",
            "Epoch 00009: val_accuracy improved from 0.90345 to 0.91724, saving model to drive/My Drive/pro_data/pro_book_res/source_model.h5\n",
            "10/10 [==============================] - 20s 2s/step - loss: 0.4073 - accuracy: 0.8965 - val_loss: 0.7838 - val_accuracy: 0.9172\n",
            "Epoch 10/30\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3821 - accuracy: 0.9284\n",
            "Epoch 00010: val_accuracy did not improve from 0.91724\n",
            "10/10 [==============================] - 18s 2s/step - loss: 0.3821 - accuracy: 0.9284 - val_loss: 0.7753 - val_accuracy: 0.9034\n",
            "Epoch 11/30\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3918 - accuracy: 0.9172\n",
            "Epoch 00011: val_accuracy improved from 0.91724 to 0.95517, saving model to drive/My Drive/pro_data/pro_book_res/source_model.h5\n",
            "10/10 [==============================] - 20s 2s/step - loss: 0.3918 - accuracy: 0.9172 - val_loss: 0.7859 - val_accuracy: 0.9552\n",
            "Epoch 12/30\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3759 - accuracy: 0.9206\n",
            "Epoch 00012: val_accuracy improved from 0.95517 to 0.98276, saving model to drive/My Drive/pro_data/pro_book_res/source_model.h5\n",
            "10/10 [==============================] - 22s 2s/step - loss: 0.3759 - accuracy: 0.9206 - val_loss: 0.7312 - val_accuracy: 0.9828\n",
            "Epoch 13/30\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3464 - accuracy: 0.9405\n",
            "Epoch 00013: val_accuracy did not improve from 0.98276\n",
            "10/10 [==============================] - 17s 2s/step - loss: 0.3464 - accuracy: 0.9405 - val_loss: 0.7315 - val_accuracy: 0.9793\n",
            "Epoch 14/30\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3448 - accuracy: 0.9465\n",
            "Epoch 00014: val_accuracy did not improve from 0.98276\n",
            "10/10 [==============================] - 18s 2s/step - loss: 0.3448 - accuracy: 0.9465 - val_loss: 0.7367 - val_accuracy: 0.9759\n",
            "Epoch 15/30\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3250 - accuracy: 0.9543\n",
            "Epoch 00015: val_accuracy did not improve from 0.98276\n",
            "10/10 [==============================] - 18s 2s/step - loss: 0.3250 - accuracy: 0.9543 - val_loss: 0.7056 - val_accuracy: 0.9828\n",
            "Epoch 16/30\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3260 - accuracy: 0.9534\n",
            "Epoch 00016: val_accuracy did not improve from 0.98276\n",
            "10/10 [==============================] - 18s 2s/step - loss: 0.3260 - accuracy: 0.9534 - val_loss: 0.6985 - val_accuracy: 0.9793\n",
            "Epoch 17/30\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3225 - accuracy: 0.9577\n",
            "Epoch 00017: val_accuracy did not improve from 0.98276\n",
            "10/10 [==============================] - 17s 2s/step - loss: 0.3225 - accuracy: 0.9577 - val_loss: 0.7111 - val_accuracy: 0.9621\n",
            "Epoch 18/30\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3261 - accuracy: 0.9560\n",
            "Epoch 00018: val_accuracy did not improve from 0.98276\n",
            "10/10 [==============================] - 18s 2s/step - loss: 0.3261 - accuracy: 0.9560 - val_loss: 0.6923 - val_accuracy: 0.9621\n",
            "Epoch 19/30\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3152 - accuracy: 0.9620\n",
            "Epoch 00019: val_accuracy did not improve from 0.98276\n",
            "10/10 [==============================] - 18s 2s/step - loss: 0.3152 - accuracy: 0.9620 - val_loss: 0.6499 - val_accuracy: 0.9793\n",
            "Epoch 20/30\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3184 - accuracy: 0.9569\n",
            "Epoch 00020: val_accuracy did not improve from 0.98276\n",
            "10/10 [==============================] - 18s 2s/step - loss: 0.3184 - accuracy: 0.9569 - val_loss: 0.6341 - val_accuracy: 0.9793\n",
            "Epoch 21/30\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3121 - accuracy: 0.9629\n",
            "Epoch 00021: val_accuracy did not improve from 0.98276\n",
            "10/10 [==============================] - 19s 2s/step - loss: 0.3121 - accuracy: 0.9629 - val_loss: 0.6432 - val_accuracy: 0.9448\n",
            "Epoch 22/30\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3209 - accuracy: 0.9620\n",
            "Epoch 00022: val_accuracy did not improve from 0.98276\n",
            "10/10 [==============================] - 19s 2s/step - loss: 0.3209 - accuracy: 0.9620 - val_loss: 0.5969 - val_accuracy: 0.9759\n",
            "Epoch 23/30\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3166 - accuracy: 0.9629\n",
            "Epoch 00023: val_accuracy did not improve from 0.98276\n",
            "10/10 [==============================] - 17s 2s/step - loss: 0.3166 - accuracy: 0.9629 - val_loss: 0.5677 - val_accuracy: 0.9828\n",
            "Epoch 24/30\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3021 - accuracy: 0.9750\n",
            "Epoch 00024: val_accuracy did not improve from 0.98276\n",
            "10/10 [==============================] - 17s 2s/step - loss: 0.3021 - accuracy: 0.9750 - val_loss: 0.5753 - val_accuracy: 0.9793\n",
            "Epoch 25/30\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2934 - accuracy: 0.9724\n",
            "Epoch 00025: val_accuracy improved from 0.98276 to 0.98621, saving model to drive/My Drive/pro_data/pro_book_res/source_model.h5\n",
            "10/10 [==============================] - 20s 2s/step - loss: 0.2934 - accuracy: 0.9724 - val_loss: 0.5179 - val_accuracy: 0.9862\n",
            "Epoch 26/30\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3174 - accuracy: 0.9594\n",
            "Epoch 00026: val_accuracy did not improve from 0.98621\n",
            "10/10 [==============================] - 18s 2s/step - loss: 0.3174 - accuracy: 0.9594 - val_loss: 0.6143 - val_accuracy: 0.9069\n",
            "Epoch 27/30\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3041 - accuracy: 0.9655\n",
            "Epoch 00027: val_accuracy improved from 0.98621 to 0.98966, saving model to drive/My Drive/pro_data/pro_book_res/source_model.h5\n",
            "10/10 [==============================] - 20s 2s/step - loss: 0.3041 - accuracy: 0.9655 - val_loss: 0.5305 - val_accuracy: 0.9897\n",
            "Epoch 28/30\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2900 - accuracy: 0.9715\n",
            "Epoch 00028: val_accuracy did not improve from 0.98966\n",
            "10/10 [==============================] - 17s 2s/step - loss: 0.2900 - accuracy: 0.9715 - val_loss: 0.5518 - val_accuracy: 0.9621\n",
            "Epoch 29/30\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2988 - accuracy: 0.9620\n",
            "Epoch 00029: val_accuracy did not improve from 0.98966\n",
            "10/10 [==============================] - 17s 2s/step - loss: 0.2988 - accuracy: 0.9620 - val_loss: 0.4910 - val_accuracy: 0.9828\n",
            "Epoch 30/30\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2856 - accuracy: 0.9741\n",
            "Epoch 00030: val_accuracy did not improve from 0.98966\n",
            "10/10 [==============================] - 18s 2s/step - loss: 0.2856 - accuracy: 0.9741 - val_loss: 0.4583 - val_accuracy: 0.9793\n",
            "source accuracy test 0.7827586206896552\n",
            "Source Classifier matrix:  [[104   0   2]\n",
            " [ 50  40   7]\n",
            " [  4   0  83]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXmEueGcsie0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "300b01bd-75b7-4ffb-c824-5689f44ef934"
      },
      "source": [
        "from keras.models import load_model\n",
        "test_x,test_y = param[\"target_data_test\"]\n",
        "param[\"source_model\"] = load_model('drive/My Drive/pro_data/pro_book_res/source_model.h5')\n",
        "\n",
        "y_pred = param[\"source_model\"].predict(test_x)\n",
        "target_accuracy_test = accuracy_score(test_y.argmax(1), y_pred.argmax(1))              \n",
        "\n",
        "print(\"target accuracy test\",target_accuracy_test)\n",
        "print(\"target Classifier matrix: \",metrics.confusion_matrix(test_y.argmax(1), y_pred.argmax(1)))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "target accuracy test 0.225\n",
            "target Classifier matrix:  [[ 9  0  0]\n",
            " [14  0  2]\n",
            " [15  0  0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwTmK0fllRcY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "563d1aa7-17cc-4b02-90f6-d3133bf7d7ac"
      },
      "source": [
        "eval_source_classifier( param,  param[\"source_model\"])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-11-06ffbc0a68c6>:10: Model.evaluate_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.evaluate, which supports generators.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
            " Source Classifier Test loss:1.11158\n",
            " Source Classifier Test accuracy:25.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0ieQv60ADTa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "param[\"source_model\"].save('drive/My Drive/pro_data/result_vgg/source_model.h5')\n",
        "# loaded_model = load_model('drive/My Drive/pro_data/result_vgg/model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqmduE5XGCjD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fc3af07c-a7b3-402d-e72c-ca16aa2bb851"
      },
      "source": [
        "# define_source_encoder()\n",
        "# define_target_encoder()\n",
        "train_target_discriminator(param)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 :  1 / 120 ; Loss: 0.8038  ( 0.8057 0.8019 ); Accuracy:  0.51171875  ( 0.5625 0.4609 )\n",
            "1 :  2 / 120 ; Loss: 0.8053  ( 0.8061 0.8046 ); Accuracy:  0.515625  ( 0.5156 0.5156 )\n",
            "1 :  3 / 120 ; Loss: 0.8051  ( 0.8070 0.8031 ); Accuracy:  0.4921875  ( 0.5234 0.4609 )\n",
            "1 :  4 / 120 ; Loss: 0.8041  ( 0.8033 0.8048 ); Accuracy:  0.4921875  ( 0.5156 0.4688 )\n",
            "1 :  5 / 120 ; Loss: 0.8017  ( 0.8040 0.7995 ); Accuracy:  0.5234375  ( 0.5781 0.4688 )\n",
            "1 :  6 / 120 ; Loss: 0.7975  ( 0.8042 0.7908 ); Accuracy:  0.51171875  ( 0.5547 0.4688 )\n",
            "1 :  7 / 120 ; Loss: 0.7977  ( 0.8060 0.7893 ); Accuracy:  0.453125  ( 0.4844 0.4219 )\n",
            "1 :  8 / 120 ; Loss: 0.8023  ( 0.8045 0.8002 ); Accuracy:  0.5  ( 0.5391 0.4609 )\n",
            "1 :  9 / 120 ; Loss: 0.8018  ( 0.8006 0.8031 ); Accuracy:  0.5078125  ( 0.5625 0.4531 )\n",
            "1 :  10 / 120 ; Loss: 0.8009  ( 0.8048 0.7971 ); Accuracy:  0.4525669664144516  ( 0.4286 0.4766 )\n",
            "1 :  11 / 120 ; Loss: 0.7932  ( 0.8047 0.7816 ); Accuracy:  0.41796875  ( 0.4688 0.3672 )\n",
            "1 :  12 / 120 ; Loss: 0.8031  ( 0.8050 0.8013 ); Accuracy:  0.4921875  ( 0.5156 0.4688 )\n",
            "1 :  13 / 120 ; Loss: 0.8016  ( 0.8009 0.8024 ); Accuracy:  0.49609375  ( 0.5781 0.4141 )\n",
            "1 :  14 / 120 ; Loss: 0.7846  ( 0.8036 0.7655 ); Accuracy:  0.49609375  ( 0.5859 0.4062 )\n",
            "1 :  15 / 120 ; Loss: 0.7862  ( 0.8044 0.7680 ); Accuracy:  0.44921875  ( 0.5234 0.3750 )\n",
            "1 :  16 / 120 ; Loss: 0.7879  ( 0.8034 0.7724 ); Accuracy:  0.45703125  ( 0.5469 0.3672 )\n",
            "1 :  17 / 120 ; Loss: 0.7855  ( 0.8040 0.7669 ); Accuracy:  0.40625  ( 0.5000 0.3125 )\n",
            "1 :  18 / 120 ; Loss: 0.7868  ( 0.8033 0.7704 ); Accuracy:  0.42578125  ( 0.5703 0.2812 )\n",
            "1 :  19 / 120 ; Loss: 0.7901  ( 0.7971 0.7830 ); Accuracy:  0.51171875  ( 0.5703 0.4531 )\n",
            "1 :  20 / 120 ; Loss: 0.8001  ( 0.8086 0.7915 ); Accuracy:  0.5797991156578064  ( 0.7143 0.4453 )\n",
            "1 :  21 / 120 ; Loss: 0.7875  ( 0.8031 0.7719 ); Accuracy:  0.43359375  ( 0.5391 0.3281 )\n",
            "1 :  22 / 120 ; Loss: 0.7867  ( 0.7987 0.7746 ); Accuracy:  0.41015625  ( 0.5547 0.2656 )\n",
            "1 :  23 / 120 ; Loss: 0.7837  ( 0.8026 0.7647 ); Accuracy:  0.40234375  ( 0.5156 0.2891 )\n",
            "1 :  24 / 120 ; Loss: 0.8031  ( 0.8013 0.8049 ); Accuracy:  0.46875  ( 0.5000 0.4375 )\n",
            "1 :  25 / 120 ; Loss: 0.7777  ( 0.8045 0.7509 ); Accuracy:  0.44140625  ( 0.4922 0.3906 )\n",
            "1 :  26 / 120 ; Loss: 0.7858  ( 0.8048 0.7668 ); Accuracy:  0.37109375  ( 0.5391 0.2031 )\n",
            "1 :  27 / 120 ; Loss: 0.7873  ( 0.8031 0.7715 ); Accuracy:  0.453125  ( 0.5234 0.3828 )\n",
            "1 :  28 / 120 ; Loss: 0.7820  ( 0.8045 0.7595 ); Accuracy:  0.4140625  ( 0.5234 0.3047 )\n",
            "1 :  29 / 120 ; Loss: 0.7860  ( 0.8014 0.7705 ); Accuracy:  0.35546875  ( 0.5078 0.2031 )\n",
            "1 :  30 / 120 ; Loss: 0.7824  ( 0.8094 0.7555 ); Accuracy:  0.4693080484867096  ( 0.5714 0.3672 )\n",
            "1 :  31 / 120 ; Loss: 0.7877  ( 0.8051 0.7702 ); Accuracy:  0.40625  ( 0.5391 0.2734 )\n",
            "1 :  32 / 120 ; Loss: 0.7798  ( 0.8034 0.7563 ); Accuracy:  0.3671875  ( 0.4844 0.2500 )\n",
            "1 :  33 / 120 ; Loss: 0.7816  ( 0.8044 0.7588 ); Accuracy:  0.4296875  ( 0.5547 0.3047 )\n",
            "1 :  34 / 120 ; Loss: 0.7709  ( 0.7993 0.7425 ); Accuracy:  0.44140625  ( 0.5781 0.3047 )\n",
            "1 :  35 / 120 ; Loss: 0.7708  ( 0.8017 0.7399 ); Accuracy:  0.4140625  ( 0.5156 0.3125 )\n",
            "1 :  36 / 120 ; Loss: 0.8045  ( 0.8026 0.8065 ); Accuracy:  0.51171875  ( 0.5547 0.4688 )\n",
            "1 :  37 / 120 ; Loss: 0.7733  ( 0.8040 0.7426 ); Accuracy:  0.4296875  ( 0.5078 0.3516 )\n",
            "1 :  38 / 120 ; Loss: 0.7800  ( 0.8005 0.7595 ); Accuracy:  0.44140625  ( 0.5469 0.3359 )\n",
            "1 :  39 / 120 ; Loss: 0.7783  ( 0.8019 0.7548 ); Accuracy:  0.41015625  ( 0.5156 0.3047 )\n",
            "1 :  40 / 120 ; Loss: 0.7869  ( 0.8074 0.7665 ); Accuracy:  0.4693080484867096  ( 0.5714 0.3672 )\n",
            "1 :  41 / 120 ; Loss: 0.7758  ( 0.8061 0.7455 ); Accuracy:  0.4296875  ( 0.5312 0.3281 )\n",
            "1 :  42 / 120 ; Loss: 0.7812  ( 0.7978 0.7646 ); Accuracy:  0.37109375  ( 0.5391 0.2031 )\n",
            "1 :  43 / 120 ; Loss: 0.7798  ( 0.8000 0.7596 ); Accuracy:  0.37109375  ( 0.5625 0.1797 )\n",
            "1 :  44 / 120 ; Loss: 0.7784  ( 0.7995 0.7573 ); Accuracy:  0.41796875  ( 0.5625 0.2734 )\n",
            "1 :  45 / 120 ; Loss: 0.7792  ( 0.7984 0.7600 ); Accuracy:  0.484375  ( 0.5391 0.4297 )\n",
            "1 :  46 / 120 ; Loss: 0.7845  ( 0.8016 0.7674 ); Accuracy:  0.37109375  ( 0.4844 0.2578 )\n",
            "1 :  47 / 120 ; Loss: 0.7816  ( 0.8001 0.7632 ); Accuracy:  0.4375  ( 0.4922 0.3828 )\n",
            "1 :  48 / 120 ; Loss: 0.7892  ( 0.8038 0.7746 ); Accuracy:  0.3515625  ( 0.5469 0.1562 )\n",
            "1 :  49 / 120 ; Loss: 0.7865  ( 0.8036 0.7694 ); Accuracy:  0.3125  ( 0.5156 0.1094 )\n",
            "1 :  50 / 120 ; Loss: 0.8008  ( 0.8094 0.7922 ); Accuracy:  0.4291294664144516  ( 0.4286 0.4297 )\n",
            "1 :  51 / 120 ; Loss: 0.7772  ( 0.8029 0.7514 ); Accuracy:  0.40234375  ( 0.5078 0.2969 )\n",
            "1 :  52 / 120 ; Loss: 0.7830  ( 0.8029 0.7631 ); Accuracy:  0.38671875  ( 0.5938 0.1797 )\n",
            "1 :  53 / 120 ; Loss: 0.7760  ( 0.8003 0.7517 ); Accuracy:  0.40234375  ( 0.5703 0.2344 )\n",
            "1 :  54 / 120 ; Loss: 0.8042  ( 0.8051 0.8033 ); Accuracy:  0.48828125  ( 0.4844 0.4922 )\n",
            "1 :  55 / 120 ; Loss: 0.7804  ( 0.8008 0.7600 ); Accuracy:  0.41015625  ( 0.5469 0.2734 )\n",
            "1 :  56 / 120 ; Loss: 0.7819  ( 0.7994 0.7644 ); Accuracy:  0.38671875  ( 0.5156 0.2578 )\n",
            "1 :  57 / 120 ; Loss: 0.7772  ( 0.8025 0.7518 ); Accuracy:  0.421875  ( 0.5703 0.2734 )\n",
            "1 :  58 / 120 ; Loss: 0.7840  ( 0.8011 0.7668 ); Accuracy:  0.36328125  ( 0.4766 0.2500 )\n",
            "1 :  59 / 120 ; Loss: 0.7753  ( 0.8036 0.7471 ); Accuracy:  0.484375  ( 0.5859 0.3828 )\n",
            "1 :  60 / 120 ; Loss: 0.8017  ( 0.8060 0.7975 ); Accuracy:  0.3861607164144516  ( 0.4286 0.3438 )\n",
            "1 :  61 / 120 ; Loss: 0.7776  ( 0.8026 0.7526 ); Accuracy:  0.44140625  ( 0.5391 0.3438 )\n",
            "1 :  62 / 120 ; Loss: 0.7836  ( 0.8013 0.7659 ); Accuracy:  0.30859375  ( 0.5000 0.1172 )\n",
            "1 :  63 / 120 ; Loss: 0.7942  ( 0.8029 0.7854 ); Accuracy:  0.47265625  ( 0.5547 0.3906 )\n",
            "1 :  64 / 120 ; Loss: 0.7795  ( 0.8006 0.7584 ); Accuracy:  0.4296875  ( 0.5781 0.2812 )\n",
            "1 :  65 / 120 ; Loss: 0.7718  ( 0.7959 0.7477 ); Accuracy:  0.38671875  ( 0.5312 0.2422 )\n",
            "1 :  66 / 120 ; Loss: 0.7735  ( 0.8011 0.7459 ); Accuracy:  0.390625  ( 0.5391 0.2422 )\n",
            "1 :  67 / 120 ; Loss: 0.7852  ( 0.7996 0.7707 ); Accuracy:  0.32421875  ( 0.5703 0.0781 )\n",
            "1 :  68 / 120 ; Loss: 0.7792  ( 0.7979 0.7605 ); Accuracy:  0.5  ( 0.6172 0.3828 )\n",
            "1 :  69 / 120 ; Loss: 0.7820  ( 0.7976 0.7663 ); Accuracy:  0.3359375  ( 0.5469 0.1250 )\n",
            "1 :  70 / 120 ; Loss: 0.7792  ( 0.8098 0.7485 ); Accuracy:  0.4185267984867096  ( 0.5714 0.2656 )\n",
            "1 :  71 / 120 ; Loss: 0.7727  ( 0.8038 0.7416 ); Accuracy:  0.421875  ( 0.5469 0.2969 )\n",
            "1 :  72 / 120 ; Loss: 0.7827  ( 0.7965 0.7688 ); Accuracy:  0.41796875  ( 0.5547 0.2812 )\n",
            "1 :  73 / 120 ; Loss: 0.7702  ( 0.7948 0.7455 ); Accuracy:  0.484375  ( 0.5781 0.3906 )\n",
            "1 :  74 / 120 ; Loss: 0.7739  ( 0.7977 0.7501 ); Accuracy:  0.44140625  ( 0.5625 0.3203 )\n",
            "1 :  75 / 120 ; Loss: 0.7658  ( 0.7880 0.7436 ); Accuracy:  0.421875  ( 0.5625 0.2812 )\n",
            "1 :  76 / 120 ; Loss: 0.7675  ( 0.7979 0.7370 ); Accuracy:  0.41015625  ( 0.5547 0.2656 )\n",
            "1 :  77 / 120 ; Loss: 0.7866  ( 0.7949 0.7782 ); Accuracy:  0.3359375  ( 0.5938 0.0781 )\n",
            "1 :  78 / 120 ; Loss: 0.7707  ( 0.8004 0.7411 ); Accuracy:  0.46484375  ( 0.6406 0.2891 )\n",
            "1 :  79 / 120 ; Loss: 0.7728  ( 0.7902 0.7554 ); Accuracy:  0.43359375  ( 0.6406 0.2266 )\n",
            "1 :  80 / 120 ; Loss: 0.7810  ( 0.8094 0.7525 ); Accuracy:  0.2924107164144516  ( 0.4286 0.1562 )\n",
            "1 :  81 / 120 ; Loss: 0.7802  ( 0.7927 0.7677 ); Accuracy:  0.328125  ( 0.5625 0.0938 )\n",
            "1 :  82 / 120 ; Loss: 0.7618  ( 0.7861 0.7375 ); Accuracy:  0.4453125  ( 0.5547 0.3359 )\n",
            "1 :  83 / 120 ; Loss: 0.7778  ( 0.7987 0.7568 ); Accuracy:  0.4296875  ( 0.5469 0.3125 )\n",
            "1 :  84 / 120 ; Loss: 0.7993  ( 0.7947 0.8040 ); Accuracy:  0.5078125  ( 0.6094 0.4062 )\n",
            "1 :  85 / 120 ; Loss: 0.7699  ( 0.7913 0.7485 ); Accuracy:  0.4140625  ( 0.5938 0.2344 )\n",
            "1 :  86 / 120 ; Loss: 0.7803  ( 0.7993 0.7612 ); Accuracy:  0.34375  ( 0.5625 0.1250 )\n",
            "1 :  87 / 120 ; Loss: 0.7690  ( 0.7860 0.7520 ); Accuracy:  0.48046875  ( 0.5781 0.3828 )\n",
            "1 :  88 / 120 ; Loss: 0.7776  ( 0.7897 0.7656 ); Accuracy:  0.3515625  ( 0.6172 0.0859 )\n",
            "1 :  89 / 120 ; Loss: 0.7782  ( 0.7961 0.7603 ); Accuracy:  0.40234375  ( 0.6172 0.1875 )\n",
            "1 :  90 / 120 ; Loss: 0.7895  ( 0.8089 0.7700 ); Accuracy:  0.3364955484867096  ( 0.5714 0.1016 )\n",
            "1 :  91 / 120 ; Loss: 0.7716  ( 0.7931 0.7500 ); Accuracy:  0.44140625  ( 0.6719 0.2109 )\n",
            "1 :  92 / 120 ; Loss: 0.7671  ( 0.7859 0.7483 ); Accuracy:  0.4296875  ( 0.5859 0.2734 )\n",
            "1 :  93 / 120 ; Loss: 0.7910  ( 0.7785 0.8035 ); Accuracy:  0.578125  ( 0.6328 0.5234 )\n",
            "1 :  94 / 120 ; Loss: 0.7772  ( 0.8020 0.7524 ); Accuracy:  0.46484375  ( 0.5859 0.3438 )\n",
            "1 :  95 / 120 ; Loss: 0.7726  ( 0.7895 0.7556 ); Accuracy:  0.3515625  ( 0.5781 0.1250 )\n",
            "1 :  96 / 120 ; Loss: 0.7982  ( 0.7923 0.8040 ); Accuracy:  0.5234375  ( 0.6094 0.4375 )\n",
            "1 :  97 / 120 ; Loss: 0.7776  ( 0.7912 0.7640 ); Accuracy:  0.3359375  ( 0.6016 0.0703 )\n",
            "1 :  98 / 120 ; Loss: 0.7679  ( 0.7995 0.7363 ); Accuracy:  0.43359375  ( 0.6016 0.2656 )\n",
            "1 :  99 / 120 ; Loss: 0.7711  ( 0.7747 0.7674 ); Accuracy:  0.5078125  ( 0.6562 0.3594 )\n",
            "1 :  100 / 120 ; Loss: 0.7851  ( 0.8075 0.7628 ); Accuracy:  0.4458705484867096  ( 0.5714 0.3203 )\n",
            "1 :  101 / 120 ; Loss: 0.7672  ( 0.7917 0.7427 ); Accuracy:  0.453125  ( 0.6328 0.2734 )\n",
            "1 :  102 / 120 ; Loss: 0.7737  ( 0.7932 0.7543 ); Accuracy:  0.37890625  ( 0.6172 0.1406 )\n",
            "1 :  103 / 120 ; Loss: 0.7788  ( 0.7939 0.7636 ); Accuracy:  0.3515625  ( 0.5781 0.1250 )\n",
            "1 :  104 / 120 ; Loss: 0.7640  ( 0.7902 0.7379 ); Accuracy:  0.48828125  ( 0.6641 0.3125 )\n",
            "1 :  105 / 120 ; Loss: 0.7704  ( 0.7891 0.7518 ); Accuracy:  0.390625  ( 0.5781 0.2031 )\n",
            "1 :  106 / 120 ; Loss: 0.7709  ( 0.7790 0.7628 ); Accuracy:  0.36328125  ( 0.6484 0.0781 )\n",
            "1 :  107 / 120 ; Loss: 0.7649  ( 0.7929 0.7368 ); Accuracy:  0.46875  ( 0.6406 0.2969 )\n",
            "1 :  108 / 120 ; Loss: 0.7734  ( 0.7823 0.7645 ); Accuracy:  0.3828125  ( 0.6406 0.1250 )\n",
            "1 :  109 / 120 ; Loss: 0.7667  ( 0.7958 0.7377 ); Accuracy:  0.4765625  ( 0.6641 0.2891 )\n",
            "1 :  110 / 120 ; Loss: 0.7873  ( 0.8054 0.7691 ); Accuracy:  0.5083705484867096  ( 0.5714 0.4453 )\n",
            "1 :  111 / 120 ; Loss: 0.7906  ( 0.7791 0.8021 ); Accuracy:  0.5546875  ( 0.6875 0.4219 )\n",
            "1 :  112 / 120 ; Loss: 0.7715  ( 0.7952 0.7479 ); Accuracy:  0.36328125  ( 0.6172 0.1094 )\n",
            "1 :  113 / 120 ; Loss: 0.7685  ( 0.7861 0.7510 ); Accuracy:  0.484375  ( 0.6875 0.2812 )\n",
            "1 :  114 / 120 ; Loss: 0.7644  ( 0.7840 0.7448 ); Accuracy:  0.390625  ( 0.5781 0.2031 )\n",
            "1 :  115 / 120 ; Loss: 0.7682  ( 0.7825 0.7540 ); Accuracy:  0.40234375  ( 0.6406 0.1641 )\n",
            "1 :  116 / 120 ; Loss: 0.7712  ( 0.7943 0.7482 ); Accuracy:  0.4453125  ( 0.6797 0.2109 )\n",
            "1 :  117 / 120 ; Loss: 0.7761  ( 0.7915 0.7607 ); Accuracy:  0.34765625  ( 0.6250 0.0703 )\n",
            "1 :  118 / 120 ; Loss: 0.7761  ( 0.7883 0.7638 ); Accuracy:  0.35546875  ( 0.6328 0.0781 )\n",
            "1 :  119 / 120 ; Loss: 0.7636  ( 0.7799 0.7473 ); Accuracy:  0.3671875  ( 0.5781 0.1562 )\n",
            "1 :  120 / 120 ; Loss: 0.7962  ( 0.8092 0.7831 ); Accuracy:  0.2611607164144516  ( 0.4286 0.0938 )\n",
            "2 :  1 / 120 ; Loss: 0.7704  ( 0.7852 0.7557 ); Accuracy:  0.41015625  ( 0.7266 0.0938 )\n",
            "2 :  2 / 120 ; Loss: 0.7684  ( 0.7733 0.7635 ); Accuracy:  0.390625  ( 0.6562 0.1250 )\n",
            "2 :  3 / 120 ; Loss: 0.7666  ( 0.7834 0.7498 ); Accuracy:  0.43359375  ( 0.6641 0.2031 )\n",
            "2 :  4 / 120 ; Loss: 0.7642  ( 0.7875 0.7409 ); Accuracy:  0.53125  ( 0.7031 0.3594 )\n",
            "2 :  5 / 120 ; Loss: 0.7573  ( 0.7790 0.7355 ); Accuracy:  0.4921875  ( 0.7188 0.2656 )\n",
            "2 :  6 / 120 ; Loss: 0.7688  ( 0.7866 0.7511 ); Accuracy:  0.5234375  ( 0.6641 0.3828 )\n",
            "2 :  7 / 120 ; Loss: 0.7605  ( 0.7719 0.7491 ); Accuracy:  0.47265625  ( 0.7656 0.1797 )\n",
            "2 :  8 / 120 ; Loss: 0.7629  ( 0.7883 0.7375 ); Accuracy:  0.41796875  ( 0.5391 0.2969 )\n",
            "2 :  9 / 120 ; Loss: 0.7589  ( 0.7803 0.7375 ); Accuracy:  0.49609375  ( 0.6562 0.3359 )\n",
            "2 :  10 / 120 ; Loss: 0.7749  ( 0.8041 0.7456 ); Accuracy:  0.4029017984867096  ( 0.5714 0.2344 )\n",
            "2 :  11 / 120 ; Loss: 0.7588  ( 0.7572 0.7604 ); Accuracy:  0.3671875  ( 0.6797 0.0547 )\n",
            "2 :  12 / 120 ; Loss: 0.7843  ( 0.7903 0.7784 ); Accuracy:  0.3359375  ( 0.6094 0.0625 )\n",
            "2 :  13 / 120 ; Loss: 0.7737  ( 0.7921 0.7553 ); Accuracy:  0.40234375  ( 0.6406 0.1641 )\n",
            "2 :  14 / 120 ; Loss: 0.7576  ( 0.7687 0.7464 ); Accuracy:  0.421875  ( 0.6562 0.1875 )\n",
            "2 :  15 / 120 ; Loss: 0.7578  ( 0.7674 0.7481 ); Accuracy:  0.453125  ( 0.6875 0.2188 )\n",
            "2 :  16 / 120 ; Loss: 0.7599  ( 0.7842 0.7356 ); Accuracy:  0.4765625  ( 0.7031 0.2500 )\n",
            "2 :  17 / 120 ; Loss: 0.7629  ( 0.7774 0.7483 ); Accuracy:  0.41015625  ( 0.6328 0.1875 )\n",
            "2 :  18 / 120 ; Loss: 0.7692  ( 0.7778 0.7607 ); Accuracy:  0.41015625  ( 0.7578 0.0625 )\n",
            "2 :  19 / 120 ; Loss: 0.7576  ( 0.7712 0.7439 ); Accuracy:  0.421875  ( 0.6406 0.2031 )\n",
            "2 :  20 / 120 ; Loss: 0.7735  ( 0.7997 0.7474 ); Accuracy:  0.4508928656578064  ( 0.7143 0.1875 )\n",
            "2 :  21 / 120 ; Loss: 0.7601  ( 0.7617 0.7585 ); Accuracy:  0.4296875  ( 0.7031 0.1562 )\n",
            "2 :  22 / 120 ; Loss: 0.7626  ( 0.7768 0.7485 ); Accuracy:  0.4296875  ( 0.6719 0.1875 )\n",
            "2 :  23 / 120 ; Loss: 0.7645  ( 0.7737 0.7553 ); Accuracy:  0.41015625  ( 0.6953 0.1250 )\n",
            "2 :  24 / 120 ; Loss: 0.7894  ( 0.7776 0.8013 ); Accuracy:  0.5390625  ( 0.6094 0.4688 )\n",
            "2 :  25 / 120 ; Loss: 0.7620  ( 0.7638 0.7602 ); Accuracy:  0.34765625  ( 0.6250 0.0703 )\n",
            "2 :  26 / 120 ; Loss: 0.7698  ( 0.7933 0.7463 ); Accuracy:  0.390625  ( 0.6250 0.1562 )\n",
            "2 :  27 / 120 ; Loss: 0.7813  ( 0.7735 0.7892 ); Accuracy:  0.5546875  ( 0.6406 0.4688 )\n",
            "2 :  28 / 120 ; Loss: 0.7772  ( 0.7876 0.7667 ); Accuracy:  0.51171875  ( 0.6172 0.4062 )\n",
            "2 :  29 / 120 ; Loss: 0.7672  ( 0.7789 0.7554 ); Accuracy:  0.3515625  ( 0.5781 0.1250 )\n",
            "2 :  30 / 120 ; Loss: 0.7757  ( 0.8097 0.7416 ); Accuracy:  0.3822544664144516  ( 0.4286 0.3359 )\n",
            "2 :  31 / 120 ; Loss: 0.7638  ( 0.7733 0.7543 ); Accuracy:  0.41796875  ( 0.7266 0.1094 )\n",
            "2 :  32 / 120 ; Loss: 0.7535  ( 0.7644 0.7425 ); Accuracy:  0.47265625  ( 0.6484 0.2969 )\n",
            "2 :  33 / 120 ; Loss: 0.7696  ( 0.7797 0.7595 ); Accuracy:  0.39453125  ( 0.6172 0.1719 )\n",
            "2 :  34 / 120 ; Loss: 0.7780  ( 0.7738 0.7823 ); Accuracy:  0.56640625  ( 0.7266 0.4062 )\n",
            "2 :  35 / 120 ; Loss: 0.7714  ( 0.7812 0.7616 ); Accuracy:  0.37109375  ( 0.6641 0.0781 )\n",
            "2 :  36 / 120 ; Loss: 0.7745  ( 0.7693 0.7798 ); Accuracy:  0.3984375  ( 0.6719 0.1250 )\n",
            "2 :  37 / 120 ; Loss: 0.7755  ( 0.7796 0.7714 ); Accuracy:  0.54296875  ( 0.7031 0.3828 )\n",
            "2 :  38 / 120 ; Loss: 0.7626  ( 0.7758 0.7495 ); Accuracy:  0.4765625  ( 0.8125 0.1406 )\n",
            "2 :  39 / 120 ; Loss: 0.7532  ( 0.7637 0.7428 ); Accuracy:  0.50390625  ( 0.6953 0.3125 )\n",
            "2 :  40 / 120 ; Loss: 0.7701  ( 0.8055 0.7348 ); Accuracy:  0.4068080484867096  ( 0.5714 0.2422 )\n",
            "2 :  41 / 120 ; Loss: 0.7718  ( 0.7750 0.7687 ); Accuracy:  0.35546875  ( 0.6484 0.0625 )\n",
            "2 :  42 / 120 ; Loss: 0.7676  ( 0.7867 0.7485 ); Accuracy:  0.453125  ( 0.7109 0.1953 )\n",
            "2 :  43 / 120 ; Loss: 0.7663  ( 0.7796 0.7530 ); Accuracy:  0.421875  ( 0.7188 0.1250 )\n",
            "2 :  44 / 120 ; Loss: 0.7866  ( 0.7775 0.7957 ); Accuracy:  0.4921875  ( 0.6016 0.3828 )\n",
            "2 :  45 / 120 ; Loss: 0.7710  ( 0.7828 0.7591 ); Accuracy:  0.46875  ( 0.7109 0.2266 )\n",
            "2 :  46 / 120 ; Loss: 0.7652  ( 0.7876 0.7428 ); Accuracy:  0.484375  ( 0.7344 0.2344 )\n",
            "2 :  47 / 120 ; Loss: 0.7700  ( 0.7829 0.7571 ); Accuracy:  0.328125  ( 0.5469 0.1094 )\n",
            "2 :  48 / 120 ; Loss: 0.7874  ( 0.7727 0.8020 ); Accuracy:  0.5625  ( 0.7500 0.3750 )\n",
            "2 :  49 / 120 ; Loss: 0.7769  ( 0.7900 0.7638 ); Accuracy:  0.3203125  ( 0.5859 0.0547 )\n",
            "2 :  50 / 120 ; Loss: 0.7811  ( 0.8087 0.7535 ); Accuracy:  0.3549107164144516  ( 0.4286 0.2812 )\n",
            "2 :  51 / 120 ; Loss: 0.7758  ( 0.7875 0.7641 ); Accuracy:  0.37109375  ( 0.6953 0.0469 )\n",
            "2 :  52 / 120 ; Loss: 0.7483  ( 0.7609 0.7357 ); Accuracy:  0.4296875  ( 0.6875 0.1719 )\n",
            "2 :  53 / 120 ; Loss: 0.7884  ( 0.7784 0.7984 ); Accuracy:  0.56640625  ( 0.7422 0.3906 )\n",
            "2 :  54 / 120 ; Loss: 0.7617  ( 0.7773 0.7461 ); Accuracy:  0.42578125  ( 0.6406 0.2109 )\n",
            "2 :  55 / 120 ; Loss: 0.7566  ( 0.7621 0.7512 ); Accuracy:  0.3828125  ( 0.6641 0.1016 )\n",
            "2 :  56 / 120 ; Loss: 0.7645  ( 0.7720 0.7569 ); Accuracy:  0.3671875  ( 0.6641 0.0703 )\n",
            "2 :  57 / 120 ; Loss: 0.7719  ( 0.7742 0.7696 ); Accuracy:  0.52734375  ( 0.6484 0.4062 )\n",
            "2 :  58 / 120 ; Loss: 0.7590  ( 0.7628 0.7552 ); Accuracy:  0.37890625  ( 0.6875 0.0703 )\n",
            "2 :  59 / 120 ; Loss: 0.7598  ( 0.7669 0.7527 ); Accuracy:  0.3984375  ( 0.6641 0.1328 )\n",
            "2 :  60 / 120 ; Loss: 0.7864  ( 0.8038 0.7690 ); Accuracy:  0.3169642984867096  ( 0.5714 0.0625 )\n",
            "2 :  61 / 120 ; Loss: 0.7675  ( 0.7842 0.7508 ); Accuracy:  0.390625  ( 0.6562 0.1250 )\n",
            "2 :  62 / 120 ; Loss: 0.7569  ( 0.7650 0.7488 ); Accuracy:  0.44140625  ( 0.7500 0.1328 )\n",
            "2 :  63 / 120 ; Loss: 0.7761  ( 0.7926 0.7597 ); Accuracy:  0.37109375  ( 0.6797 0.0625 )\n",
            "2 :  64 / 120 ; Loss: 0.7622  ( 0.7731 0.7513 ); Accuracy:  0.3984375  ( 0.6875 0.1094 )\n",
            "2 :  65 / 120 ; Loss: 0.7612  ( 0.7729 0.7494 ); Accuracy:  0.4765625  ( 0.7188 0.2344 )\n",
            "2 :  66 / 120 ; Loss: 0.7697  ( 0.7809 0.7585 ); Accuracy:  0.48046875  ( 0.6953 0.2656 )\n",
            "2 :  67 / 120 ; Loss: 0.7759  ( 0.7820 0.7697 ); Accuracy:  0.390625  ( 0.7109 0.0703 )\n",
            "2 :  68 / 120 ; Loss: 0.7595  ( 0.7737 0.7454 ); Accuracy:  0.46484375  ( 0.6094 0.3203 )\n",
            "2 :  69 / 120 ; Loss: 0.7630  ( 0.7766 0.7494 ); Accuracy:  0.45703125  ( 0.6875 0.2266 )\n",
            "2 :  70 / 120 ; Loss: 0.7737  ( 0.8070 0.7404 ); Accuracy:  0.3900669664144516  ( 0.4286 0.3516 )\n",
            "2 :  71 / 120 ; Loss: 0.7631  ( 0.7762 0.7500 ); Accuracy:  0.43359375  ( 0.7344 0.1328 )\n",
            "2 :  72 / 120 ; Loss: 0.7768  ( 0.7769 0.7767 ); Accuracy:  0.39453125  ( 0.7266 0.0625 )\n",
            "2 :  73 / 120 ; Loss: 0.7596  ( 0.7769 0.7422 ); Accuracy:  0.4375  ( 0.7031 0.1719 )\n",
            "2 :  74 / 120 ; Loss: 0.7723  ( 0.7855 0.7590 ); Accuracy:  0.44140625  ( 0.6016 0.2812 )\n",
            "2 :  75 / 120 ; Loss: 0.7598  ( 0.7650 0.7546 ); Accuracy:  0.3828125  ( 0.6406 0.1250 )\n",
            "2 :  76 / 120 ; Loss: 0.7820  ( 0.7670 0.7969 ); Accuracy:  0.5390625  ( 0.6641 0.4141 )\n",
            "2 :  77 / 120 ; Loss: 0.7618  ( 0.7676 0.7560 ); Accuracy:  0.52734375  ( 0.6953 0.3594 )\n",
            "2 :  78 / 120 ; Loss: 0.7672  ( 0.7878 0.7466 ); Accuracy:  0.34765625  ( 0.6016 0.0938 )\n",
            "2 :  79 / 120 ; Loss: 0.7629  ( 0.7747 0.7511 ); Accuracy:  0.39453125  ( 0.7188 0.0703 )\n",
            "2 :  80 / 120 ; Loss: 0.7810  ( 0.8080 0.7540 ); Accuracy:  0.2767857164144516  ( 0.4286 0.1250 )\n",
            "2 :  81 / 120 ; Loss: 0.7653  ( 0.7885 0.7421 ); Accuracy:  0.3671875  ( 0.5859 0.1484 )\n",
            "2 :  82 / 120 ; Loss: 0.7668  ( 0.7820 0.7516 ); Accuracy:  0.42578125  ( 0.7734 0.0781 )\n",
            "2 :  83 / 120 ; Loss: 0.7667  ( 0.7745 0.7590 ); Accuracy:  0.50390625  ( 0.7344 0.2734 )\n",
            "2 :  84 / 120 ; Loss: 0.7816  ( 0.7572 0.8059 ); Accuracy:  0.515625  ( 0.6562 0.3750 )\n",
            "2 :  85 / 120 ; Loss: 0.7602  ( 0.7735 0.7469 ); Accuracy:  0.36328125  ( 0.6328 0.0938 )\n",
            "2 :  86 / 120 ; Loss: 0.7611  ( 0.7635 0.7586 ); Accuracy:  0.421875  ( 0.7656 0.0781 )\n",
            "2 :  87 / 120 ; Loss: 0.7568  ( 0.7652 0.7484 ); Accuracy:  0.45703125  ( 0.7500 0.1641 )\n",
            "2 :  88 / 120 ; Loss: 0.7654  ( 0.7816 0.7492 ); Accuracy:  0.40625  ( 0.6875 0.1250 )\n",
            "2 :  89 / 120 ; Loss: 0.7585  ( 0.7702 0.7468 ); Accuracy:  0.3984375  ( 0.6719 0.1250 )\n",
            "2 :  90 / 120 ; Loss: 0.7790  ( 0.8092 0.7488 ); Accuracy:  0.3325892984867096  ( 0.5714 0.0938 )\n",
            "2 :  91 / 120 ; Loss: 0.7637  ( 0.7778 0.7495 ); Accuracy:  0.41796875  ( 0.7031 0.1328 )\n",
            "2 :  92 / 120 ; Loss: 0.7658  ( 0.7729 0.7586 ); Accuracy:  0.44140625  ( 0.8125 0.0703 )\n",
            "2 :  93 / 120 ; Loss: 0.7814  ( 0.7599 0.8030 ); Accuracy:  0.546875  ( 0.6719 0.4219 )\n",
            "2 :  94 / 120 ; Loss: 0.7806  ( 0.7678 0.7935 ); Accuracy:  0.59375  ( 0.7266 0.4609 )\n",
            "2 :  95 / 120 ; Loss: 0.7603  ( 0.7630 0.7576 ); Accuracy:  0.546875  ( 0.6797 0.4141 )\n",
            "2 :  96 / 120 ; Loss: 0.7640  ( 0.7657 0.7623 ); Accuracy:  0.36328125  ( 0.6953 0.0312 )\n",
            "2 :  97 / 120 ; Loss: 0.7700  ( 0.7820 0.7581 ); Accuracy:  0.37890625  ( 0.7031 0.0547 )\n",
            "2 :  98 / 120 ; Loss: 0.7547  ( 0.7734 0.7360 ); Accuracy:  0.44921875  ( 0.7656 0.1328 )\n",
            "2 :  99 / 120 ; Loss: 0.7583  ( 0.7732 0.7434 ); Accuracy:  0.43359375  ( 0.7891 0.0781 )\n",
            "2 :  100 / 120 ; Loss: 0.8002  ( 0.8102 0.7902 ); Accuracy:  0.4614955484867096  ( 0.5714 0.3516 )\n",
            "2 :  101 / 120 ; Loss: 0.7642  ( 0.7794 0.7491 ); Accuracy:  0.41796875  ( 0.6797 0.1562 )\n",
            "2 :  102 / 120 ; Loss: 0.7719  ( 0.7843 0.7595 ); Accuracy:  0.3671875  ( 0.6328 0.1016 )\n",
            "2 :  103 / 120 ; Loss: 0.7623  ( 0.7758 0.7488 ); Accuracy:  0.44921875  ( 0.7188 0.1797 )\n",
            "2 :  104 / 120 ; Loss: 0.7620  ( 0.7696 0.7544 ); Accuracy:  0.40234375  ( 0.7344 0.0703 )\n",
            "2 :  105 / 120 ; Loss: 0.7763  ( 0.7719 0.7806 ); Accuracy:  0.5234375  ( 0.7109 0.3359 )\n",
            "2 :  106 / 120 ; Loss: 0.7640  ( 0.7627 0.7653 ); Accuracy:  0.48046875  ( 0.7344 0.2266 )\n",
            "2 :  107 / 120 ; Loss: 0.7601  ( 0.7735 0.7467 ); Accuracy:  0.44921875  ( 0.6641 0.2344 )\n",
            "2 :  108 / 120 ; Loss: 0.7745  ( 0.7637 0.7853 ); Accuracy:  0.6015625  ( 0.7031 0.5000 )\n",
            "2 :  109 / 120 ; Loss: 0.7645  ( 0.7877 0.7412 ); Accuracy:  0.42578125  ( 0.6641 0.1875 )\n",
            "2 :  110 / 120 ; Loss: 0.7800  ( 0.7987 0.7614 ); Accuracy:  0.4520089328289032  ( 0.8571 0.0469 )\n",
            "2 :  111 / 120 ; Loss: 0.7712  ( 0.7905 0.7519 ); Accuracy:  0.3828125  ( 0.6094 0.1562 )\n",
            "2 :  112 / 120 ; Loss: 0.7586  ( 0.7710 0.7462 ); Accuracy:  0.43359375  ( 0.7500 0.1172 )\n",
            "2 :  113 / 120 ; Loss: 0.7641  ( 0.7723 0.7558 ); Accuracy:  0.37890625  ( 0.6562 0.1016 )\n",
            "2 :  114 / 120 ; Loss: 0.7611  ( 0.7684 0.7538 ); Accuracy:  0.39453125  ( 0.6797 0.1094 )\n",
            "2 :  115 / 120 ; Loss: 0.7747  ( 0.7906 0.7589 ); Accuracy:  0.33203125  ( 0.5859 0.0781 )\n",
            "2 :  116 / 120 ; Loss: 0.7724  ( 0.7825 0.7623 ); Accuracy:  0.5234375  ( 0.6562 0.3906 )\n",
            "2 :  117 / 120 ; Loss: 0.7547  ( 0.7741 0.7353 ); Accuracy:  0.47265625  ( 0.7500 0.1953 )\n",
            "2 :  118 / 120 ; Loss: 0.7638  ( 0.7632 0.7644 ); Accuracy:  0.52734375  ( 0.7656 0.2891 )\n",
            "2 :  119 / 120 ; Loss: 0.7538  ( 0.7650 0.7425 ); Accuracy:  0.5  ( 0.7188 0.2812 )\n",
            "2 :  120 / 120 ; Loss: 0.8017  ( 0.8019 0.8016 ); Accuracy:  0.5758928656578064  ( 0.7143 0.4375 )\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjUVgnCo3Zim",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "param[\"source_dicriminator\"].save_weights('drive/My Drive/pro_data/pro_book_res/discriminator_s_weights.hdf5')\n",
        "param[\"target_dicriminator\"].save_weights('drive/My Drive/pro_data/pro_book_res/discriminator_t_weightsd.hdf5')\n",
        "param[\"target_encoder\"].save_weights('drive/My Drive/pro_data/pro_book_res/encoder_t_weights.hdf5')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kd12vTzBGDux",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "06ced3aa-8695-49e8-912b-6cb7835fa238"
      },
      "source": [
        "from keras.models import load_model\n",
        "# test_x,test_y = param[\"target_data_test\"]\n",
        "test_x,test_y = param[\"target_data_test\"]\n",
        "model = load_model('drive/My Drive/pro_data/pro_book_res/source_model.h5')\n",
        "path_target_discriminator = 'drive/My Drive/pro_data/pro_book_res/discriminator_t_weightsd.hdf5'\n",
        "model.load_weights(path_target_discriminator, by_name=True)\n",
        "y_pred = model.predict(test_x)\n",
        "target_accuracy_test = accuracy_score(test_y.argmax(1), y_pred.argmax(1))              \n",
        "\n",
        "print(\"target accuracy test\",target_accuracy_test)\n",
        "print(\"target Classifier matrix: \",metrics.confusion_matrix(test_y.argmax(1), y_pred.argmax(1)))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "target accuracy test 0.225\n",
            "target Classifier matrix:  [[ 9  0  0]\n",
            " [16  0  0]\n",
            " [15  0  0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teQ5UDAk-nrw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "81a61a65-2e43-467c-ab52-449d3c01bb75"
      },
      "source": [
        "from keras.models import load_model\n",
        "# test_x,test_y = param[\"target_data_test\"]\n",
        "test_x,test_y = param[\"source_data_test\"]\n",
        "# model = load_model('drive/My Drive/pro_data/pro_book_res/source_model.h5')\n",
        "# path_target_discriminator = 'drive/My Drive/pro_data/pro_book_res/discriminator_t_weightsd.hdf5'\n",
        "# model.load_weights(path_target_discriminator, by_name=True)\n",
        "y_pred = model.predict(test_x)\n",
        "target_accuracy_test = accuracy_score(test_y.argmax(1), y_pred.argmax(1))              \n",
        "\n",
        "print(\"source accuracy test\",target_accuracy_test)\n",
        "print(\"source Classifier matrix: \",metrics.confusion_matrix(test_y.argmax(1), y_pred.argmax(1)))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "source accuracy test 0.36551724137931035\n",
            "source Classifier matrix:  [[106   0   0]\n",
            " [ 97   0   0]\n",
            " [ 87   0   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQ5ys7NCYa5t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "param[\"target_dicriminator\"].save_weights('drive/My Drive/pro_data/pro_book_res/discriminator_t_weights_iter_200.hdf5')\n",
        "param[\"target_encoder\"].save_weights('drive/My Drive/pro_data/pro_book_res/encoder_t_weights_iter_200.hdf5')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HypVMDUaqWU0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        },
        "outputId": "43ce82bb-b500-4705-cae0-dbbe465e03e1"
      },
      "source": [
        "eval_target_classifier(param)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_25\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_18 (InputLayer)        (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "vggface_vgg16 (Model)        multiple                  14714688  \n",
            "_________________________________________________________________\n",
            "flatten_15 (Flatten)         (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "class_dense1 (Dense)         (None, 400)               10035600  \n",
            "_________________________________________________________________\n",
            "class_bn1 (BatchNormalizatio (None, 400)               1600      \n",
            "_________________________________________________________________\n",
            "class_act1 (Activation)      (None, 400)               0         \n",
            "_________________________________________________________________\n",
            "class_drop1 (Dropout)        (None, 400)               0         \n",
            "_________________________________________________________________\n",
            "class_dense2 (Dense)         (None, 100)               40100     \n",
            "_________________________________________________________________\n",
            "class_bn2 (BatchNormalizatio (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "class_act2 (Activation)      (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "class_drop2 (Dropout)        (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "class_dense_last (Dense)     (None, 2)                 202       \n",
            "_________________________________________________________________\n",
            "class_bn_last (BatchNormaliz (None, 2)                 8         \n",
            "_________________________________________________________________\n",
            "class_act_last (Activation)  (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 24,792,598\n",
            "Trainable params: 24,791,594\n",
            "Non-trainable params: 1,004\n",
            "_________________________________________________________________\n",
            " Target Classifier Test loss:0.75421\n",
            " Target Classifier Test accuracy:50.94%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVK8Drr3t14z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "8890f378-09ba-44d2-e861-caad9f4c81cf"
      },
      "source": [
        "# target_classifier = get_source_classifier(param[\"target_encoder\"])\n",
        "\n",
        "# path_target_discriminator = 'drive/My Drive/pro_data/result_vgg/discriminator_t_weights.hdf5'\n",
        "# target_classifier.load_weights(path_target_discriminator, by_name=True)\n",
        "model = param[\"source_model\"]\n",
        "path_target_discriminator = 'drive/My Drive/pro_data/result_vgg/discriminator_t_weights_iter_400.hdf5'\n",
        "model.load_weights(path_target_discriminator, by_name=True)\n",
        "model.compile(optimizer = opt_classifier(param), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "test_x,test_y = param[\"target_data_test\"]\n",
        "yt_pred = model.predict(test_x)\n",
        "target_accuracy_test = accuracy_score(test_y.argmax(1), yt_pred.argmax(1))              \n",
        "\n",
        "print(\"target accuracy test\",target_accuracy_test)\n",
        "print(\"target Classifier matrix: \",metrics.confusion_matrix(test_y.argmax(1), yt_pred.argmax(1)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "target accuracy test 0.49061032863849763\n",
            "target Classifier matrix:  [[  0 217]\n",
            " [  0 209]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFLFI9hVKa-W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "245eab33-0e5a-42e4-aad5-5a7aeaeb03d1"
      },
      "source": [
        "define_target_encoder()\n",
        "model = get_source_classifier(param[\"target_encoder\"])\n",
        "path = 'drive/My Drive/pro_data/result_vgg/source_model.h5'\n",
        "target_discriminator = 'drive/My Drive/pro_data/result_vgg/discriminator_t_weights_iter_400.hdf5'\n",
        "path_target_encoder = 'drive/My Drive/pro_data/result_vgg/encoder_t_weights.hdf5'\n",
        "model.load_weights(path, by_name=True)\n",
        "model.load_weights(path_target_encoder, by_name=True)\n",
        "\n",
        "model.compile(optimizer = opt_classifier(param), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "test_x,test_y = param[\"target_data_test\"]\n",
        "yt_pred = model.predict(test_x)\n",
        "target_accuracy_test = accuracy_score(test_y.argmax(1), yt_pred.argmax(1))              \n",
        "\n",
        "print(\"target accuracy test\",target_accuracy_test)\n",
        "print(\"target Classifier matrix: \",metrics.confusion_matrix(test_y.argmax(1), yt_pred.argmax(1)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "target accuracy test 0.5093896713615024\n",
            "target Classifier matrix:  [[217   0]\n",
            " [209   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72k0QMFAxLD1",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjwFc7HPyZNv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval_source_classifier(param, model):\n",
        "        \n",
        "        (test_x, test_y) = param[\"target_data_test\"]\n",
        "        src_datagen = ImageDataGenerator(data_format='channels_last', \n",
        "                                        rescale=1./255)\n",
        "                      \n",
        "        model.compile(loss='categorical_crossentropy', optimizer=self.src_optimizer, metrics=['accuracy'])\n",
        "\n",
        "        scores = model.evaluate_generator(src_datagen.flow(test_x, test_y),10000)\n",
        "        print('%s %s Classifier Test loss:%.5f'%(dataset.upper(), domain, scores[0]))\n",
        "        print('%s %s Classifier Test accuracy:%.2f%%'%(dataset.upper(), domain, float(scores[1])*100))            \n",
        "            \n",
        "    def eval_target_classifier(param, source_model, target_discriminator, dataset='svhn'):\n",
        "        source_classifier_model = load_model(source_model)\n",
        "        source_classifier_model.load_weights(target_discriminator, by_name=True)\n",
        "        source_classifier_model.summary()\n",
        "        eval_source_classifier(param,source_classifier_model, domain='Target')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VduSEY_-xPmv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Path to source classifier model to test/evaluate\n",
        "path_source_classifier = \n",
        "# Path to target discriminator model to test/evaluate\n",
        "path_target_classifier= \n",
        "\n",
        "define_target_encoder(args.source_weights)\n",
        "\n",
        "train_target_discriminator(param)\n",
        "eval_target_classifier(path_source_classifier, path_target_classifier)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUoeAyyhw_lJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = load_model('/content/drive/My Drive/pro_data/‏final_result_notB/source_classifier.h5')\n",
        "model.load_weights('/content/drive/My Drive/pro_data/pro_book_res/disc_target.hdf5', by_name=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}